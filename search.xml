<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[异步导出框架介绍（一）]]></title>
    <url>%2F2019%2F12%2F20%2FasyExportFrame%2F</url>
    <content type="text"><![CDATA[一. 背景在我们开发中很多项目都有Excel下载导出的需求，如最近在我司很火的盘古-基地项目，启航-uni（选品中心）项目等。现有的Excel导出功能是同步的，即在页面点击“下载”会同步发送http请求至应用后台，由后台进行处理（数据获取及导出为Excel）后向浏览器发送http的response，从而浏览器下载Excel文件。这里存在两个问题，第一是基本所有需要用到Excel导出功能的项目都会自己去实现一套”ExcelExportUtil”，各个应用的实现也基本没啥差别。这就带来了很多重复的代码，加大各应用的维护成本。第二个问题是如果下载的文件过大（特别是当下载的文件中含有图片内容）时，会导致浏览器请求断开，这样就无法获取到下载文件了。因此很多业务方都有异步导出Excel的需求，然而重头开发的成本又太高了。为解决上述的这些问题，所以我在闲暇时刻开发了此异步导出框架～ 二. 系统架构介绍系统设计架构如下图所示。按照系统划分，可以分为四块：1、数据库 2、导出框架 3、客户端实现 4、下载后台。 1、数据库数据库是实现本框架的基础。当使用本框架进行数据导出时，客户端需要实现一个数据导出的功能，即当用户点击页面进行“下载”时，会向db创建一条数据导出的任务数据。 CREATE TABLE `ExportTask` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `userId` bigint(11) unsigned NOT NULL DEFAULT '0' COMMENT '用户ID', `formName` varchar(200) NOT NULL DEFAULT '' COMMENT '报表名称', `exportType` int(4) unsigned NOT NULL DEFAULT '0' COMMENT '导出业务类型', `status` tinyint(4) unsigned NOT NULL DEFAULT '0' COMMENT '任务状态 0:未完成 1:运行中 2:错误 3:已完成', `key` varchar(200) NOT NULL DEFAULT '' COMMENT '文件对应key', `retryNum` int(4) unsigned NOT NULL DEFAULT '0' COMMENT '重试次数', `rule` varchar(1024) NOT NULL DEFAULT '{}' COMMENT '查询规则', `downloadCount` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '下载次数', `downloadTime` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '最后一次下载时间', `ip` varchar(200) NOT NULL DEFAULT '' COMMENT '用户下载ip地址', `visible` tinyint(4) unsigned NOT NULL DEFAULT '1' COMMENT '是否可见', `isDeleted` tinyint(1) unsigned NOT NULL DEFAULT '0' COMMENT '是否删除 1:已删除; 0:未删除', `created` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '订单创建时间', `updated` int(11) unsigned NOT NULL DEFAULT '0' COMMENT '更新时间', PRIMARY KEY (`id`), KEY `idx_userId_exportType_status` (`userId`,`exportType`,`status`), KEY `idx_created` (`created`), KEY `idx_updated` (`updated`) ) ENGINE=InnoDB AUTO_INCREMENT=1000 DEFAULT CHARSET=utf8mb4 COMMENT='导出任务表'; 其中有一个很重要的字段——rule，表示查询规则。当业务方需要获取各自业务的下载数据时，一般都是通过接口的方式获取数据的。此时的入参一般来说是一个包含了各种查询字段的对象。 导出任务表的rule字段就是存放着这些对象的json字符串。 2、导出框架逻辑上很简单易懂，首先我们有一个ExportDataService的接口，然后有一个抽象的AbstractExportDataService实现了ExportDataService的接口。另外有一个ExportDataServiceFactory工厂，负责注册和获取具体的导出服务实现。在AbstractExportDataService中，有一个exportDataMethod方法，此方法负责将数据导出到文件系统（即CDN），并会返回文件上传到文件系统后生成的fileKey。获取fileKey后，会向db中更新此条导出任务的fileKey。 3、客户端实现客户端的实现也十分简便容易。首先需要实现创建导出任务的方法，当用户点击页面进行“下载”时，会向db中insert一条数据。而后，客户端需要实现一个自定义的导出定时任务，并向ExportDataServiceFactory中注册对应的导出服务实现，从而从db中获取对应类型的导出任务并获取数据，最后导出Excel。这里都以Excel导出为例，是因为现今的业务方导出的方式都是Excel。但仔细看整个业务架构的同学可以发现，整个业务架构并不是局限于“Excel”，理论上此服务框架可以适用于各种形式的数据导出。 4、下载后台下载后台顾名思义，会将用户想要导出的数据集中的放到一个后台进行管理。解决了现今各应用导出数据杂乱、无法管理的问题。另外对于权限控制，对接了蘑菇街外网的权限控制——用户需要进行蘑菇街登陆后才可进行相关服务的操作如筛选下载文件及文件下载等。 三. 待优化点1、兼容多种数据导出模式，而不局限于Excel（暂时没有这样的业务需求2333） 2、失败重试任务机制开发：现在只有一个正常导出的定时任务，没有对导出失败的情况做兼容。譬如rpc接口超时或者服务不可用的情况。因此之后会考虑开发失败重试的定时任务去解决异常的导出任务。 3、监控打点：对各业务方的调用情况进行监控及打点。主要是为了避免某些异常导出任务会对线上db产生不可预估的影响，从而影响其他正常的业务运行。 在下一节我们会讲下此异步导出框架的伪代码实现～]]></content>
      <tags>
        <tag>Export</tag>
        <tag>Frame</tag>
        <tag>Tech</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fork-Join 框架详解（一）]]></title>
    <url>%2F2019%2F11%2F10%2FforkJoin-1%2F</url>
    <content type="text"><![CDATA[1. 什么是Fork-Join框架Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架，主要思路就是递归或者“分而治之”。Fork-Join框架使用工作窃取（work-stealing）算法来进行并行计算。 2. 使用简介要使用Fork-Join框架，首先需要建立一个ForkJoin任务(ForkJoinTask)。Fork-Join框架提供了两个ForkJoinTask的子类供我们建立ForkJoin任务：a.RecursiveAction：用于没有返回结果的任务b.RecursiveTask:用于有返回结果的任务 3. 举个例子斐波那契数列我们都知道，我们在最开始编程的时候肯定使用过“递归”的方式来计算斐波那契数列，那么今天我们也用Fork-Join框架来实现下斐波那契数列的计算。 首先是传统递归的方法： private static int calcFib(int n) { if (n &lt;= 2) { return 1; } else return calcFib(n - 1) + calcFib(n - 2); } 我们试着运算下： public static void main(String[] args) { System.out.println(calcFib(10)); } 答案很显然是55。 那么我们用Fork-Join框架来实现下： 首先建立一个FibonacciTask的类，因为我们需要有返回值的任务，因此FibonacciTask需要继承RecursiveTask类，并覆盖其compute方法。 fork方法的作用就是将任务放到当前线程的工作队列当中去，join则是等待任务的完成。 如果要计算的斐波那契数列大于2，我们就把任务分成n-1和n-2， 等n-1和n-2任务计算完毕后将这两者的结果合并即可 public class FibonacciTask extends RecursiveTask&lt;Long&gt; { private Long num; public FibonacciTask(Long num) { this.num = num; } @Override protected Long compute() { if (num &lt;= 2) { return 1L; } FibonacciTask fibonacciTask1 = new FibonacciTask(num - 1); fibonacciTask1.fork(); FibonacciTask fibonacciTask2 = new FibonacciTask(num - 2); fibonacciTask2.fork(); return fibonacciTask1.join() + fibonacciTask2.join(); } } 我们试着通过Fork-Join框架来计算下。首先我们建立创建一个Fork-Join任务，即FibonacciTask 类。而后创建一个ForkJoinPool，即实现Fork-Join任务的线程池。然后调用invoke方法获取任务结果即可。 public static void main(String[] args) { FibonacciTask fibonacciTask = new FibonacciTask(10L); ForkJoinPool pool = new ForkJoinPool(); Long result = pool.invoke(fibonacciTask); System.out.println("result:" + result); } 4. 总结细心的同学会发现，使用Fork-Join框架实现的斐波那契数列的时间复杂度并不好，如果我们计算下两个方式的执行时间，会发现传统的效率要比Fork-Join框架好多了。很好理解，Fork-Join框架执行的时候，需要不断地拆分任务和合并任务结果，这些操作需要消耗时间的。当任务不复杂或不大时，fork和join操作占据了整个程序的大部分时间。 但是对于复杂的计算密集型的任务，使用Fork-Join框架效率是比较高的。 另外相对于一般的线程池实现，Fork-Join框架的优势体现在对任务的处理上，即工作窃取（work-stealing）算法。在普通线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行，那么该线程进入等待。而Fork-Join框架中，如果某个子任务由于等待另外一个子任务的完成而无法继续运行时，处理该子任务的线程会主动寻找其他尚未运行的子任务来执行。这种方式减少了线程的等待时间，提高了性能。 在下一节我们会讲下Fork-Join框架内部的一些实现～]]></content>
      <tags>
        <tag>Fork-Join</tag>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fork-Join 框架详解（一）]]></title>
    <url>%2F2019%2F08%2F17%2FforkJoin-2%2F</url>
    <content type="text"><![CDATA[介绍 1. 什么是Fork-Join框架Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架，主要思路就是递归或者“分而治之”。Fork-Join框架使用工作窃取（work-stealing）算法来进行并行计算。 2. 使用及研究要使用Fork-Join框架，首先需要建立一个ForkJoin任务(ForkJoinTask)。Fork-Join框架提供了两个ForkJoinTask的子类供我们建立ForkJoin任务：a.RecursiveAction：用于没有返回结果的任务b.RecursiveTask:用于有返回结果的任务 // ready to write sth public final ForkJoinTask&lt;V&gt; fork() { Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this; } 进入workQueue.push方法 final void push(ForkJoinTask&lt;?&gt; task) { ForkJoinTask&lt;?&gt;[] a; ForkJoinPool p; int b = base, s = top, n; if ((a = array) != null) { // ignore if queue removed int m = a.length - 1; // fenced write for task visibility U.putOrderedObject(a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, task); U.putOrderedInt(this, QTOP, s + 1); if ((n = s - b) &lt;= 1) { if ((p = pool) != null) p.signalWork(p.workQueues, this); } else if (n &gt;= m) growArray(); } } 这方法看得我一脸懵逼，什么s、m的，看都看不懂呢。。那么sm究竟是什么，让我们一探究竟！ static final int INITIAL_QUEUE_CAPACITY = 1 &lt;&lt; 13; // 10000000000000 static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 26; ... volatile int base; // index of next slot for poll int top; // index of next slot for push ForkJoinTask&lt;?&gt;[] array; // the elements (initially unallocated) ... WorkQueue(ForkJoinPool pool, ForkJoinWorkerThread owner) { this.pool = pool; this.owner = owner; // Place indices in the center of array (that is not yet allocated) base = top = INITIAL_QUEUE_CAPACITY &gt;&gt;&gt; 1; // 01000000000000 } 可以看到，base就是表示“双端队列中下一个将被取出的元素的索引值”，top表示“下一个将被放入双端队列中的元素的索引值”。 可以看到，base和top在初始化时，被定义为01000000000000;这个位置是双端队列最大长度的中心（MAXIMUM_QUEUE_CAPACITY的中心位置即是INITIAL_QUEUE_CAPACITY） m就是ForkJoinTask任务队列的尾部，那么U、ABASE、ASHIFT和QTOP又是什么玩意儿？ // Unsafe mechanics. Note that some are (and must be) the same as in FJP private static final sun.misc.Unsafe U; private static final int ABASE; private static final int ASHIFT; private static final long QTOP; ... ... ... U = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; wk = WorkQueue.class; Class&lt;?&gt; ak = ForkJoinTask[].class; QTOP = U.objectFieldOffset (wk.getDeclaredField("top")); QLOCK = U.objectFieldOffset (wk.getDeclaredField("qlock")); QCURRENTSTEAL = U.objectFieldOffset (wk.getDeclaredField("currentSteal")); ABASE = U.arrayBaseOffset(ak); int scale = U.arrayIndexScale(ak); if ((scale &amp; (scale - 1)) != 0) throw new Error("data type scale not a power of two"); ASHIFT = 31 - Integer.numberOfLeadingZeros(scale); sun.misc.Unsafe U: 因为Java不能直接访问操作系统底层，而是通过本地方法来访问。Unsafe类提供了硬件级别的原子操作。ABASE: arrayBaseOffset方法是一个本地方法，可以获取数组第一个元素的偏移地址。因此ABASE就表示ForkJoinTask数组的第一个元素的偏移地址。ASHIFT: 返回无符号整型i的最高非零位前面的0的个数QTOP:]]></content>
      <tags>
        <tag>Fork-Join</tag>
        <tag>Concurrent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC Aop对Controller方法拦截失效]]></title>
    <url>%2F2019%2F06%2F15%2FcontrollerAop%2F</url>
    <content type="text"><![CDATA[介绍这次做了一个新项目，项目中各个操作接口都需要验证一把权限，那我首先想到的就是通过Spring的Aop去做一层拦截。然而问题来了：在xml中配置了切面后开始测试，我首先跑了一把单测——调用Controller里面的方法，嗯，没有问题，方法被拦截了。然后我本地起了一个tomcat，准备通过访问URL的方式来进行接口调用，然而！失败了！没有被拦截住 1. 配置相关首先，来看下我的配置 applicationContext.xml 部分配置: &lt;context:component-scan base-package="com.xxx.*"/&gt; &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt; spring-servlet.xml 部分配置: &lt;mvc:annotation-driven /&gt; &lt;context:component-scan base-package="com.xxx.controller"/&gt; 看起来是没啥问题，为了能让CGLIB进行代理，配置了&lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt;，那究竟是哪出问题了呢？其实还在于&lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt;这个配置。这个配置是配置在了applicationContext.xml中的，实际应该配置在spring-servlet.xml中。 2. 原因探寻我们知道，Spring和SpringMVC是两个不同的容器，并且SpringMVC是Spring的子容器。子容器可以访问父容器中的内容，但父容器不能访问子容器中的内容。一开始，我将&lt;aop:aspectj-autoproxy proxy-target-class=”true”/&gt;配置在了applicationContext.xml中，也就是在父级Spring容器中，当Spring加载父容器的时候就会去找切入点，但应该被拦截的controller其实是在子容器中的，父容器是无法访问子容器的，因此拦截失败。如果配置在spring-servlet.xml中，那么问题就解决了～]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>Controller</tag>
        <tag>SpringMVC</tag>
        <tag>Aop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RequestParam注解和RequestBody的区别]]></title>
    <url>%2F2019%2F05%2F21%2FcontrollerRequest%2F</url>
    <content type="text"><![CDATA[介绍配合例子来讲下@RequestParam和@RequestBody的区别 1. @RequestParam首先，@RequestParam 注解可以接受GET和POST请求，请求的参数会自动转换赋值到注解的变量上。 给一个例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445@RequestMapping("login") @ResponseBody public String login(@RequestParam(value="userName") String userName, @RequestParam(value="password") String password)&#123; return "userName:" + userName + " " + "password:" + password; &#125;``` 上述代码会将请求中的userName和password参数的值赋给对应的变量上述代码等价于：```java@RequestMapping("login2") @ResponseBody public String login2(HttpServletRequest request, HttpServletResponse response)&#123; String userName = request.getParameter("userName"); String password = request.getParameter("password"); return "userName:" + userName + " " + "password:" + password; &#125;``` 可以用postman来模拟下get请求：```java127.0.0.1:8080/login?userName=baba&amp;password=erzi``` 结果如下：```javauserName:baba password:erzi``` 用post请求也是一样的，postman的post请求参数如下：```java[&#123;"key":"Content-Type","name":"Content-Type","value":"application/x-www-form-urlencoded","description":"","type":"text"&#125;]：``` 要在请求的Body中使用key-value的方式写入请求参数：```javauserName:babapassword:12345 2. @RequestBody@RequestBody 注解是用来接收json格式的数据，然后将json string转换成controller中对应的数据对象。 @RequestBody 是处理HttpEntity传递过来数据的，在get请求中，因为没有HttpEntity，所以@RequestBody不能用于解析get请求。post请求中，通过HttpEntity传递的参数，我们可以在请求头中声明数据的类型Content-Type为application/json 此例中入参是一个map，我们也可以自定义一个实体对象，这也是完全ok的： 1234567@RequestMapping("userInfo") @ResponseBody public String QcWorkOrderListDisplay(@RequestBody Map&lt;String, String&gt; userMap)&#123; String userName = userMap.get("userName"); String password = userMap.get("password"); return "userName:" + userName + " " + "password:" + password; &#125; 请求如下： 127.0.0.1:8080/userInfo postman的请求头信息如下： [{"key":"Content-Type","name":"Content-Type","value":"application/json","description":"","type":"text"}] 请求Body如下： { "userName":"baba", "password":"erzi" } 结果还是和上面是一致的。]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>RequestParam</tag>
        <tag>RequestBody</tag>
        <tag>Controller</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lombok之Data注解的坑]]></title>
    <url>%2F2019%2F05%2F05%2FLombokAnnotationData%2F</url>
    <content type="text"><![CDATA[I. 问题在开发中有一次遇到了一个问题——在前后端交互的时候，后端在解析一个类的字段时抛出了一个npe，然而前端确认了确实传了该字段。这个问题就比较奇怪了，最后发现该字段在前后端中的展示是不一致的。并且这个类上应用了Lombok的@Data注解。那么究竟是怎么回事呢？ II. Case还原1. 首先给出一个类：User，使用了@Data注解，注意看到User类中有一个字段名字是“mPn”123456789@Datapublic class User implements Serializable &#123; private static final long serialVersionUID = -8767742709604940714L; private String name; private Integer sex; private String mPn;&#125; 2. 然后写一个controller123456789@RequestMapping("test")@ResponseBodypublic JsonReturn Test()&#123; User user = new User(); user.setName("John"); user.setSex(1); user.setMPn("18888888888"); return new JsonReturn(new Status(BizCodeEnum.SUCCESS.getCode()), user);&#125; 可以看到，mPn的setter方法是setMPn 其中的JsonReturn是我们自己写的返回给前端的结果封装类，没啥特别的： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class JsonReturn &#123; private Status status; private Object result; public static JsonReturn success(Object result)&#123; return new JsonReturn(new Status(1001) , result); &#125; public static JsonReturn failed(int code , String msg)&#123; return new JsonReturn(new Status(code , msg)); &#125; public static JsonReturn custom(int code , String msg , Object result)&#123; return new JsonReturn(new Status(code , msg) , result); &#125; public JsonReturn(Status status) &#123; this.status = status; &#125; public JsonReturn(Status status, Object result) &#123; this.status = status; this.result = result; &#125; public Status getStatus() &#123; return status; &#125; public void setStatus(Status status) &#123; this.status = status; &#125; public Object getResult() &#123; return result; &#125; public void setResult(Object result) &#123; this.result = result; &#125;&#125; 3. 本地启动一个tomcat，来访问下localhost:8080/test吧：1&#123;"status":&#123;"code":1001,"msg":null&#125;,"result":&#123;"name":"John","sex":1,"mpn":"18888888888”&#125;&#125; 告诉我你看到了什么？！浏览器前端展示出的mPn字段竟然是mpn！！！ 以上就还原了开头所说的问题现场了。 Ⅲ. 分析那么究竟是怎么回事？在java bean规范当中，类似于mPn这样的字段的setter方法应该如下setmPn，而不是Lombok的@Data注解生成的setMPn（问题就是Lombok在生成此类getter setter方法的时候将开头字母大写了，详情可见Lombok源码），这样当Spring将后端数据返回给前端时，就会出现问题。 所以为了避免这样的问题，我一般都手动用IDEA创建getter setter方法，但是会用@ToString注解来省略toString方法～ Ⅳ. Reference[1]. @Data注解时生成的getter,setter方法在有些属性会有问题！！！ #1861）[2]. Names of Getters and Setters generated by Lombok are buggy for attributes like “eMail” or “aValue” etc #757）]]></content>
      <tags>
        <tag>Lombok</tag>
        <tag>Data</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring核心逻辑]]></title>
    <url>%2F2019%2F04%2F20%2FSpringInAction-3%2F</url>
    <content type="text"><![CDATA[介绍前面已经有两篇关于Spring的文章了。在第一篇中大致讲了一些Spring的基础且常见的一些问题；第二篇写了关于aop的一些知识；这一篇主要基于Spring的源码讲一些Spring内部的核心逻辑 I. 容器的基本实现 XML的验证模式：Spring检验验证模式的方式是判断XML中是否包含“DOCTYPE”，如果包含则为dtd，否则为xsd 12345/** * The token in a XML document that declares the DTD to use for validation * and thus that DTD validation is being used. */private static final String DOCTYPE = "DOCTYPE"; EntityResolver的作用：使得项目本身提供一个如何寻找dtd声明的方法，即由程序来寻找dtd声明的过程。验证文件默认的加载方式是通过URL进行网络下载获取，因此会造成延迟，用户体验也不好，一般来说是将验证文件放置在工程中。 对于不同的验证模式，org.springframework.beans.factory.xml.DelegatingEntityResolver#resolveEntity方法可以将验证文件的URL转换为工程中对应的地址文件。 123456789101112@Override public InputSource resolveEntity(String publicId, String systemId) throws SAXException, IOException &#123; if (systemId != null) &#123; if (systemId.endsWith(DTD_SUFFIX)) &#123; return this.dtdResolver.resolveEntity(publicId, systemId); &#125; else if (systemId.endsWith(XSD_SUFFIX)) &#123; return this.schemaResolver.resolveEntity(publicId, systemId); &#125; &#125; return null; &#125; 默认标签的解析？4种类型 alias import beans 扩展Spring自定义标签配置的步骤：1.创建一个需要扩展的组件2.定义一个xsd文件描述组件内容3.创建文件，实现BeanDefinationParse接口，来解析xsd文件中的定义和组件4.创建Handler文件，扩展自NamespaceHandlerSupport，目的是将组件注册到Spring容器5.编写Spring.handlers和Spring.schemas文件 自定义标签的解析：根据对应的bean获取对应的命名空间，根据命名空间解析对应的处理器，然后根据用户自定义处理器进行解析 Spring处理循环依赖：在创建单例bean时，为了避免循环依赖，Spring创建bean的原则是不等bean创建完成就会将创建bean的ObjectFactory提早曝光，即将ObjectFactory加入缓存中，一旦下个bean创建时需要依赖上一个bean则直接使用ObjectFactory。 bean加载的步骤：1.转换对应的beanName，比如去除FactoryBean的修饰符（‘&amp;’），取指定alias所表示的最终beanName2.尝试从缓存中加载单例3.bean实例化4.原型模式的依赖检查：如果存在循环依赖则会抛异常5.检测parentBeanFactory：如果缓存中没有数据则尝试从父类工厂加载6.将存储XML配置文件的GernericBeanDefinition转化为RootBeanDefinition7.寻找依赖：初始化bean首先会初始化bean所对应的依赖8.针对不同的scope进行bean的创建9.类型转换：将bean的类型转换为requiredType想要的类型 代码见：org.springframework.beans.factory.support.AbstractBeanFactory#doGetBean FactoryBean：一般情况下Spring通过反射机制来实例化bean。但在某些情况中实例化bean比较复杂，需要在中提供很多配置，这时实现用户可以通过实现FactoryBean接口定制实例化bean的逻辑，简化配置。 单例bean创建：1.检查缓存是否已经加载过2.若没有加载，则记录beanName的正在加载状态3.加载单例前记录加载状态：这是为了方便对循环依赖进行检测4.通过ObjectFactory实例化bean5.加载单例后的方法调用：与步骤3有点类似，当bean加载结束后需要移除bean正在加载状态的记录6.将结果记录至缓存并删除bean过程中所记录的各种辅助状态7.返回处理结果 代码见：org.springframework.beans.factory.support.DefaultSingletonBeanRegistry#getSingleton(java.lang.String, org.springframework.beans.factory.ObjectFactory&lt;?&gt;) Spring循环依赖：包括构造器循环依赖和setter循环依赖。Spring中将循环依赖的处理分成了3种情况。1.构造器循环依赖，表示构造器注入构成的循环依赖，此依赖无法解决，只能抛出BeanCurrentlyInCreationException异常。Spring容器将每一个正在创建的bean标识符放在一个“当前创建bean池”中，如果在创建bean的过程中发现自己已经在“当前创建bean池”中，就抛出异常表示循环依赖。 2.setter循环依赖：表示通过setter注入方式构成的循环依赖。Spring容器通过提前暴露刚完成构造器注入但未完成其他步骤（如setter注入）的bean来完成的，但只能解决单例作用域的bean循环依赖。通过提前暴露一个单例工厂方法，从而使其他bean可以引用到该bean。3.prototype范围的依赖处理：对于“prototype”作用域bean，Spring容器无法完成依赖注入，因为Spring容器不进行缓存“prototype”作用域的bean，因此无法提前暴露该bean。 创建bean实例：1.如果工厂方法不为空则使用工厂方法创建bean实例2.解析构造函数并进行构造函数的实例化，bean中可能会存在多个构造函数，每个构造函数的参数不同，Spring会根据参数及类型判断使用哪个构造函数进行初始化。但是这个过程比较耗费性能，因此会采用缓存机制。对于实例的创建Spring中分为两种情况：一种是通用的实例化，另一种是带有参数的实例化。带参数的实例化逻辑相当复杂，Spring把大量精力放在了构造函数以及参数的匹配上。3.实例化策略：如果beanDefinition.getMethodOverrides()为空，即用户没有使用replace或者lookup的配置方法，那么直接用反射创建实例；否则用动态代理，保证在调用方法时会被相应的拦截器增强。 代码见：org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory#createBeanInstance ClassPathXmlApplicationContext初始化过程：1.初始化前准备，比如对系统属性或者环境变量进行准备及验证2.初始化BeanFactory，并进行XML读取：ClassPathXmlApplicationContext包含着BeanFactory提供的一切特征，这一步将复用BeanFactory中的配置文件读取解析及其他功能。3.对BeanFactory进行各种功能填充：比如@Qualifier与@Autowired注解（但是事实上在Spring4.0中，org.springframework.context.support.AbstractRefreshableApplicationContext#customizeBeanFactory方法中已经没有设置setAutowireCandidateResolver属性对于 @Autowired之类的注解进行处理，这一步到了org.springframework.beans.factory.annotation.CustomAutowireConfigurer#postProcessBeanFactory）4.子类覆盖方法做额外的处理：在这一步里主要是激活注册BeanFactoryPostProcessor，BeanFactoryPostProcessor的一个典型应用就是PropertyPlaceholderConfigurer，这个类专门用于xml中出现类似于这样的变量引用：${xxx.xx}时，查找变量所在的配置文件。5.激活各种BeanFactory处理器6.注册拦截bean创建的bean处理器，这里只做注册，真正调用是在getBean时7.为上下文初始化Message源，即对不同语言的消息体进行国际化处理8.初始化应用消息广播器，并放入applicationEventMulticasterbean中9.留给子类来初始化其他bean10.在所有注册的bean中查找listener bean，注册到消息广播器中11.初始化剩下的单例（非惰性）12.完成刷新过程，通知生命周期处理器lifecycleProcessor刷新过程，同时发出ContextRefershEvent进行通知 代码见：org.springframework.context.support.AbstractApplicationContext#refresh II. 事务： 事务属性的获取规则：如果方法中存在事务属性，则使用方法上的属性，否则使用方法所在类上的属性，如果方法所在类的属性还是没有搜寻到对应的事务属性，那么再搜寻接口中的方法，若还是没有，最后尝试搜寻接口的类上的声明。 代码见：org.springframework.transaction.interceptor.AbstractFallbackTransactionAttributeSource#computeTransactionAttribute Spring支持两种事务的处理，声明式事务以及编程式事务，以下是事务的处理逻辑：1.获取事务的属性2.加载配置中配置的TransactionManager3.对于不同的事务使用不同的处理逻辑：声明式事务与编程式事务处理的区别有两点。第一点是事务属性上，编程式事务处理是不需要有事务属性的；第二点是TransactionManager上，CallbackPreferringPlatformTransactionManager实现了PlatformTransactionManager接口，暴露出一个用于执行事务回调的方法。这两点区别都可以用作事务处理方式的判断。4.在目标方法执行前获取事务并收集事务信息5.执行目标方法6.一但出现异常，尝试异常处理：默认只对RuntimeException及Error回滚7.提交事务前的事务信息清除8.提交事务 Spring事务回滚的执行逻辑：1.调用自定义触发器，包括回滚前，完成回滚后的调用2.真正的回滚逻辑：当保存的事物信息中有保存点信息时，使用保存点进行回滚，常用于嵌入式事务的处理。对于嵌入式事务，内嵌的事务处理并不会影响外部事物的回滚；若保存的事务信息中的事务为新事务，则直接回滚，多用于单独事务的处理；当事务信息表明存在事务，但又不是上述两种情况，多数用于JTA，只做回滚标识，提交时统一不提交。 代码见：org.springframework.transaction.support.AbstractPlatformTransactionManager#processRollback 事务处理的收尾工作：1.设置事务状态为完成，以避免重复调用2.如果当前事务是新的同步状态，需要将绑定到当前线程的事务信息清除3.如果是新事务，需要进行清除资源的工作4.如果事务执行前有事务挂起，那当前事务执行结束后需要将挂起的事务恢复。 事务提交：事务不是直接提交的，当事务状态中有保存点信息则不会提交；当事务非新事务时也不会执行提交操作，这一点主要是考虑到了内嵌事务的情况，对于内嵌事务，spring中正常处理是在内嵌事务开始前设置保存点，一旦内嵌事务异常需要回滚则根据保存点回滚，如果内嵌事务正常，也不会单独提交，而是由最外层事务负责提交。 III.]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring的AOP解析及使用]]></title>
    <url>%2F2019%2F03%2F24%2FSpringInAction-2%2F</url>
    <content type="text"><![CDATA[介绍第一篇中大致讲了一些Spring的基础且常见的一些问题。这一篇，将什么我还没想好 - -，先瞎几把写了。 好吧，开玩笑的，我想先写关于aop的一些知识 I. 什么是面向切面编程（Aspect-Oriented Programming，AOP）？假设我们对某些类或方法需要统一处理，比如在进入这个方法时、退出方法时做点啥，最简单直接的方式就是在每个方法的前后都写入我们需要的逻辑。乍一看貌似没有啥问题。但是仔细一想，诶！不太对，我们是不是用了太多重复的逻辑，不管从代码的整洁美观上来说还是从系统侵入上来说，这都不是一种优雅的方法。 那么有没有一种相对优雅且对代码侵入小的方式来完成这样的功能呢？ 面向切面编程（AOP）就是这样的一种方式。我们可以通过声明的方式定义一个功能以何种方式在何处应用，而不需要对受到影响的类或方法的代码作出影响。 和传统的面向对象编程（OOP）的“纵向”编程方式不同，AOP的编程方式是“横向”的。AOP将那些影响了多个类的公共行为封装到一个可重用模块，并将其名为“Aspect”，即切面。利用切面可以减少系统的重复代码，降低模块间的耦合度，有利于系统的升级与维护。 II. 切面中的相关术语描述“切面”的常用术语有通知（advice）、切点（pointcut）和连接点（join point）： 1. 通知：切面要完成的工作被称为通知（advice），其定义了切面是什么以及什么时候使用，并且定义了什么时候执行工作。 Spring AOP 提供了5种类型的通知（Advice）： 前置通知（Before）：在目标方法被调用之前调用通知功能。 后置通知（After）：在目标方法完成之后调用通知，无论该方法是否发生异常。 后置返回通知（After-returning）：在目标方法成功执行之后调用通知。 后置异常通知（After-throwing）：在目标方法抛出异常后调用通知。 环绕通知（Around）：通知包裹了被通知的方法，在被通知的方法调用之前和调用之后执行自定义的行为。 2. 连接点（Join point）：连接点是在应用执行过程中能够插入切面的一个点。这个点可以是类的某个方法调用前、调用后、方法抛出异常后等。切面代码可以利用这些点插入到应用的正常流程之中，并添加行为。 3. 切点（Pointcut）：“通知”定义了切面的“什么”和“何时”，切点则定义了“何处”，即在什么地方应用切面（比如某个包下的某个方法）。切点会匹配通知所要织入的一个或多个连接点。 4. 切面（Aspect）：切面是通知和切点的结合。通知和切点共同定义了切面的全部内容——切面是什么，在何时和何处完成相应的功能。 5. 引入（Introduction）：引入允许我们向现有的类添加新方法或属性。 Spring允许引入新的接口到任何被通知的对象。例如，你可以使用一个引入使任何对象实现 IsModified接口，来简化缓存。Spring中要使用Introduction, 可有通过DelegatingIntroductionInterceptor来实现通知，通过DefaultIntroductionAdvisor来配置Advice和代理类要实现的接口 6. 织入(Weaving)：织入是把切面应用到目标对象来创建新的代理对象的过程。在目标对象的生命周期里有多个点可以进行织入：编译器，类加载期以及运行期。Spring AOP的切面是在运行时被织入，原理是使用了动态代理技术。Spring支持两种方式生成代理对象：JDK动态代理和CGLib，默认的策略是如果目标类是接口，则使用JDK动态代理技术，否则使用Cglib来生成代理。另外，Spring只支持方法级别的连接点。 III. 在Spring中使用AOPSpring是借助AspectJ的切点表达式语言来定义切面的。Spring只支持以下几种AspectJ的指示器： arg()：限制连接点匹配参数为指定类型的执行方法 @args()：限制连接点匹配参数由指定注解标注的执行方法 execution()：匹配连接点的执行方法 this()：限制连接点匹配AOP代理的bean引用为指定类型的类 target：限制连接点匹配目标对象为指定类型的类 @target()：限制连接点匹配特定的执行对象，这些对象对应的类具有指定类型的注解 within()：限制连接点匹配指定的类型 @within()：限制连接点匹配指定注解所标注的类型 @annotation：限制匹配带有指定注解的连接点 接下来讲讲在Spring中使用AOP的两种方法 3.1 用注解实现首先我们需要有一个主题来定义切面的切点，以下的Performance接口为例： 1、定义切面的目标123public interface Performance &#123; void perform();&#125; 然后我们实现下Performance接口，写一个“魔术表演”的实现： 12345678@Servicepublic class MagicPerformance implements Performance &#123; @Override public void perform() &#123; System.out.println("Magic!"); &#125;&#125; 2、定义切面下面的代码展示了一个Audience类（观众），它定义了一个切面： 12345678910111213141516171819202122232425262728@Aspect@Componentpublic class Audience &#123; @Pointcut("execution(* aop.Performance.perform(..))") public void performance() &#123; &#125; @Before("performance()") public void silenceCellPhone() &#123; System.out.println("silenceCellPhone"); &#125; @Before("performance()") public void takeSeats() &#123; System.out.println("takeSeats"); &#125; @AfterReturning("performance()") public void applause() &#123; System.out.println("applause"); &#125; @AfterThrowing("performance()") public void demandRefund() &#123; System.out.println("demandRefund"); &#125;&#125; Audience类使用了@Aspect注解进行标注，它表示了Audience不仅仅是一个POJO，还是一个切面。 可以在上面的代码中看到我们用到了以下几个Aspect注解来声明通知，分别是：@Before-在演出前手机调成静音并按座位坐好 @AfterReturning -演出成功了鼓掌 @AfterThrowing-演出失败则要求退票 另外，可以看到有一个有趣的现象——Audience类中后四个方发都在切点表达式中使用了”performance()”，而”performance()”这个方法真正的使用了切点表达式，并且上面用@Pointcut注解标注，这是一个没有具体逻辑的空方法。 这是为了复用切点，因此使用@Pointcut来定义切点，然后在其他注解中引用定义好的切点。 切点表达式1execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern)throws-pattern?) 括号中各个pattern分别表示 修饰符匹配（modifier-pattern?）、返回值匹配（ret-type-pattern）、类路径匹配（declaring-type-pattern?）、方法名匹配（name-pattern）、参数匹配（(param-pattern)）、异常类型匹配（throws-pattern?），其中后面跟着“?”的是可选项。 我们使用的表达式是这样的：execution(* aop.Performance.perform(..))，按照上面的介绍，可以分析出是匹配aop.Performance中的perform方法 3、启用切面代理按照如上的步骤，Audience也只是Spring中一个bean，即使我们使用了@Aspect注解进行标注，但是缺少了以下的一步，注解并不会被解析，也不会转换为切面的代理： 我们可以使用JavaConfig的@EnableAspectJAutoProxy注解在Audience类上进行标注启用自动代理。当然也可以使用XML进行配置：&lt;aop:aspectj-autoproxy /&gt;，在本例中是使用了XML配置。 4、来验证下123456789public class SpringAopTest &#123; public static void main(String[] args) &#123; ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext("spring/refer.xml"); Performance performance = ctx.getBean(Performance.class); performance.perform(); &#125;&#125; 结果如下： 1234silenceCellPhonetakeSeatsMagic!applause 5、环绕通知上面的切面的前置和后置通知其实可以使用环绕通知来一并实现： 12345678910111213141516171819@Aspect@Componentpublic class Audience2 &#123; @Pointcut("execution(* aop.Performance.perform(..))") public void performance() &#123; &#125; @Around("performance()") public void watchPerformance(ProceedingJoinPoint pjp) &#123; try &#123; System.out.println("silenceCellPhone"); System.out.println("takeSeats"); pjp.proceed(); System.out.println("applause"); &#125; catch (Throwable e) &#123; System.out.println("demandRefund"); &#125; &#125;&#125; 3.2 用xml配置实现使用XML来配置，那么首先我们把Audience类的Aspect注解全部移除： 1234567891011121314151617181920212223242526272829@Componentpublic class Audience3 &#123; public void silenceCellPhone() &#123; System.out.println("silenceCellPhone"); &#125; public void takeSeats() &#123; System.out.println("takeSeats"); &#125; public void applause() &#123; System.out.println("applause"); &#125; public void demandRefund() &#123; System.out.println("demandRefund"); &#125; public void watchPerformance3(ProceedingJoinPoint pjp) &#123; try &#123; System.out.println("silenceCellPhone"); System.out.println("takeSeats"); pjp.proceed(); System.out.println("applause"); &#125; catch (Throwable e) &#123; System.out.println("demandRefund"); &#125; &#125;&#125; 然后我们直接xml中声明环绕通知： 1234567&lt;aop:config&gt; &lt;aop:aspect id="audienceAspect" ref="audience3"&gt; &lt;aop:pointcut id="performance" expression="execution(* aop.Performance.perform(..))"/&gt; &lt;aop:around pointcut-ref="performance" method="watchPerformance3"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; 结果还是一样的，就不多赘述～]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring框架常用知识解析]]></title>
    <url>%2F2019%2F03%2F16%2FSpringInAction-1%2F</url>
    <content type="text"><![CDATA[介绍之前一直想看Spring相关的源码及书籍并且想总结下相关的知识点，大约在18年11月份的时候看了《Spring源码深度解析》，当时看的情况实在一般，也没好意思写总结。这次又看了一本书《Spring实战》（Spring in action），觉得可以稍微总结下Spring中常让人疑惑的、或者说最被人关注的一些问题～ 1. 什么是控制反转（IOC）？什么是依赖注入？在传统的编程方式中，每个对象管理他所依赖的对象的引用，对象的生存周期是由引用此对象的对象来决定的。而在Spring中，所有的对象都由容器来统一管理，也就是说，决定对象生存周期的不再是引用该对象的对象，而是容器，在这种意义上来说，控制得到了反转。控制反转（IOC）是通过“依赖注入”（DI）来实现的。 依赖注入，是指程序运行过程中，如果需要调用另一个对象协助时，无须在代码中创建被调用者，而是依赖于外部的注入。DI带来的很大一点优势就是“松耦合”。 在Java中依赖注入有以下三种实现方式：构造器注入Setter方法注入接口注入 那组件之间依赖又是如何注入的呢？创建应用组件之间协作的行为称为装配（wiring），接下来会仔细讲讲Spring的装配。 2. Spring容器容纳Bean的两种方式：Spring存在多种容器，可以归为两种类型：一种是bean工厂即BeanFactory；一种是应用上下文，即ApplicationContext，它基于BeanFactory构建，并提供了应用框架级别的服务。但ApplicationContext在BeanFactory的基础上还提供了以下的功能：• 支持国际化的文本消息• 统一的资源文件读取方式，如URL和文件• 在监听器中注册的bean的事件 除此之外，BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才对该Bean进行加载实例化，这样，我们就不能发现一些存在的Spring的配置问题。而ApplicationContext则相反，它是在容器启动时，一次性创建了所有的Bean。这样，在容器启动时，我们就可以发现Spring中存在的配置错误。 这两种容器构成了Spring中IOC容器的基础。 2. 通过Spring的IOC装配Bean的三种机制：基于XML的显式配置基于􏰽􏰾􏰿􏰾􏹂􏱨􏰳􏱪􏰲􏰴JavaConfig的配置（@Configuration 和 @Bean）基于注解的隐式的bean发现机制和自动装配（@Component @Service 等） 这样生成的bean核心是通过反射来完成的。一般建议使用自动配置的机制，少用显示的配置。 3. 在Spring中用基于XML配置的方式装配Bean要通过xml来注入Bean，首先需要声明一个beans的根标签，然后通过bean子标签和和专门的应用配置选项声明那些需要IOC容器创建的Bean。例如： &lt;beans&gt; &lt;bean name="userDao" class="com.xxx.UserDaoImpl"/&gt; &lt;bean name="userService" class="com.xxx. UserServiceImpl"&gt; &lt;!-- 注入userDao对象,需要set方法--&gt; &lt;property name="userDao" ref="userDao"/&gt; &lt;/bean&gt; &lt;/beans&gt; 其中name是指明IOC创建后该对象的名称（可以用id替换），class指明了这个类的完全限定名，IOC通过上述信息利用反射来帮用户创建对应的类实例。要获取userService的实例可以通过ApplicationContext类（一般使用ClassPathXmlApplicationContext，默认加载classpath路径下的文件——即编译后的WEB-INF/classes目录；还有一个FileSystemXmlApplicationContext，它在指定的文件系统路径下查找配置文件）去加载已声明好的xml配置文件。 4. 通过xml来进行依赖注入的具体实现形式还记得在前面（1）我们说过在Java中依赖注入有三种实现方式：1. 构造器注入 2. Setter方法注入 3. 接口注入 1. 构造器注入：通过xml去装配bean，具体到构造器注入，有两种基本的配置方案：一是元素，二是使用Spring 3.0引入的c-命名空间。 假设UserServiceImpl在构造器中依赖UserDao类，那么可以按照以下的配置方案： &lt;beans&gt; &lt;bean id="userDao" class="com.xxx.UserDaoImpl"/&gt; &lt;bean id="userService" class="com.xxx. UserServiceImpl"&gt; &lt;constructor-arg ref="userDao"/&gt; &lt;/bean&gt; &lt;/beans&gt; 上述配置中的“ref”表示这是一种引用，而不是字面量“userDao”，也可以使用“value”表明给定的值是以字面量的形式注入的。 在构造器中装配集合可以按照如下配置去做： &lt;constructor-arg&gt; &lt;list&gt; &lt;value&gt;x&lt;value/&gt; &lt;value&gt;xx&lt;value/&gt; &lt;value&gt;xxx&lt;value/&gt; &lt;/list&gt; &lt;/constructor-arg&gt; 当然，如果list中是对象，则需要使用“”标签来替代“” 2. Setter方法注入： &lt;bean id="userDao" class="com.xxx.UserDaoImpl"/&gt; &lt;bean id="userService" class="com.xxx. UserServiceImpl"&gt; &lt;property name="userDao" ref="userDao"/&gt; &lt;/bean&gt; 标签为属性的Setter方法提供的功能与标签为构造器提供的功能是一样的。上述例子中，它应用了userDao的bean，通过setUserDao()方法可以将其注入到userDao属性中。 3. 接口注入：接口注入比较麻烦，因为需要通过继承接口来完成注入，带有侵入性。Spring并不支持接口注入的方式。 5. 通过JavaConfig来装配BeanSpring对Java配置的支持是由@Configuration和@Bean来实现的。@Configuration注解与＜beans/＞标签作用类似，@Bean所起到的作用与类似。被@Configuration所注解的类，表示这个类是一个配置类，该类的主要目的是作为bean定义的资源；由@Bean注解的方法会告知Spring这个方法将会实例化、配置和初始化一个新对象，这个对象要注册为Spring应用上下文中的bean。 @Configuration public class BeanConfiguration { @Bean public UserDao userDao(){ return new UserDaoImpl(); } @Bean public UserService userService(){ UserServiceImpl userService = new UserServiceImpl(); bean.setUserDao(userDao()); return userService; } } 类似于上述的加载方法，我们可以通过AnnotationConfigApplicationContext来加载BeanConfiguration.class，从而获取应用上下文及UserService对象实例，运行结果与xml配置一样。 在3.1版本中，Spring引入了bean profile功能。要使用profile要首先确保所有的bean定义到一个或多个profile中，并且确保对应环境的profile处于激活（active）状态。通过@Profile注解可以指定某个bean处于哪个环境（dev、pre或online）。 6. 通过Spring注解来自动化装配BeanSpring在2.5版本以后支持用注解的方式来配置依赖注入。可以用注解的方式来替代xml方式的bean描述，可以将bean描述转移到组件类的内部，只需要在相关类上、方法上或者字段声明上使用注解即可。 Spring在两个角度来实现自动化装配：1. 组件扫描（component scanning）自动发现应用上下文中所创建的bean 2. 自动装配（autowiring）自动满足bean之间的依赖。 通过@ComponentScan注解或者Spring context命名空间&lt;context: component-scan&gt;元素，可以启用组件扫描。 注解装配在Spring中是默认关闭的。所以需要在Spring文件中配置打开，参考如下的xml配置： &lt;beans&gt; &lt;context:annotation-config/&gt; ... &lt;/beans&gt; 下面是几种比较重要的注解类型： @Required：该注解应用于设值方法。 @Autowired：该注解应用于构造器方法、属性的setter方法（其实类的任何方法都可以）和变量。@Autowired是通过byType（类型）来装配bean，因此当类型一致时，需要通过@Qualifier来注明具体是哪一个bean。另外有一个注解为@Resource，这个注解是Java自带的，@Resource的作用相当于 @Autowired，区别是@Resource默认按byName自动注入，但也可以指定为byType注入。 @Qualifier：该注解和@Autowired注解搭配使用，用于消除特定bean自动装配的歧义。 JSR-250 Annotations：Spring支持基于JSR-250 注解的以下注解，@Resource、@PostConstruct 和 @PreDestroy。 7. Bean的生命周期与传统Java应用中bean的生命周期不同，Spring中bean的生命周期要复杂的多，bean装载到Spring应用上下文中的典型生命周期过程如下： 1.实例化； 2.填充属性：将值和bean的引用注入到bean对应的属性中； 3.调用BeanNameAware的setBeanName()方法：如果bean实现了BeanNameAware接口，Spring将bean的ID传递给setBeanName()方法； 4.调用BeanFactoryAware的setBeanFactory()方法：如果bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory()方法，将BeanFactory容器实例传入； 5.调用ApplicationContextAware的setApplicationContext()方法：如果bean实现了ApplicationContextAware接口，将调用setApplicationContext()方法把bean所在的应用上下文的引用传入进来。 步骤3、4、5可以表述为“激活Aware方法” 6.调用BeanPostProcessor的预初始化方法：如果bean实现了BeanPostProcessor接口，将调用ProcessBeforeInitialization()方法 7.调用InitializingBean的afterPropertiesSet()方法：如果bean实现了InitializingBean接口，将调用afterPropertiesSet()方法。类似地，若bean使用init-method声明来初始化方法，此方法也会被调用 8.调用BeanPostProcessor的初始化后方法：如果bean实现了BeanPostProcessor接口，将调用postAfterInitialization()方法 9.使用bean：bean已经可以被使用，将一直留在应用上下文中，直到应用上下文被销毁 10.调用DisposableBean的destory()方法：如果bean实现了DisposableBean接口，将调用destory()方法。类似地，若bean使用destory-method声明来销毁方法，也会调用这个方法。 11.bean生命周期结束 8. Spring中Bean的作用域Spring定义了多种作用域，可以基于这些作用域创建bean，包括： 单例（Singleton）：整个应用中，只创建bean的一个实例 原型（Prototype）：每次注入或者通过Spring应用上下文获取的时候，都会创建一个新的bean实例 会话（Session）：在Web应用中，为每个会话创建一个bean实例 请求（Request）：在Web应用中，为每个请求创建一个bean实例 单例是默认的作用域。如果想要用原型级别的作用域。对于使用组建扫描来发现声明bean，可以在bean的类上使用@Scope注解，将其声明为原型。 同样，如果通过xml配置，可以使用标签的scope属性来设置作用域： &lt;bean id="userDao"&gt; clasee="xxx.UserDao" scope="prototype" /&gt; ... 在典型的电子商务应用中，都会有一个代表购物车的bean，这个时候使用Session级别的作用域无疑是十分合适的。]]></content>
      <tags>
        <tag>Spring</tag>
        <tag>框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GC、垃圾收集器与内存分配]]></title>
    <url>%2F2019%2F03%2F10%2FGCAndAllocation%2F</url>
    <content type="text"><![CDATA[介绍本次博文分为以下几块：1. 简单介绍各种GC算法 2. 各种垃圾收集器介绍与应用的场合 3. 对象内存分配及相关回收策略介绍 Ⅰ. 垃圾回收算法 标记-清除（Mark-Sweep）算法这是最基本的算法，分为“标记”和“清除”两个阶段：首先标记出要回收的对象，标记完成后统一进行回收。不足点有二：第一是效率低，两个阶段的效率都不高；第二是会存在大量不连续的空间碎片，这也许会导致因为无法找到连续内存而无法分配对象从而触发不必要的GC。 复制（Copying）算法复制算法将内存划分为大小相等的两块，每次都只使用其中的一块，当这一块用完后，会将存活对象复制到另一块空间中，然后将原本的空间进行清理。因此不存在空间碎片的情况，算法实现简单，一般运行情况也比较高校，但此算法直接将可用内存缩小一半，代价较高。并且如果内存中的都是一些“寿命”较长的对象，并且这些对象总内存较大时，使用复制算法的效率就不高了——复制这些大又老的对象时间性价比比较低。因此，现在很多虚拟机都将复制算法应用于新生代。并且为了配合复制算法，将内存划分为一块较大的Eden区域，以及两块较小的Survivor区域，每次使用Eden以及一块Survivor空间。HotSpot虚拟机默认Eden和Survivor的空间比例为8:1。 标记-整理（Mark-Compact）算法一般应用于老年代。此算法基于“标记-清除”算法，标记过程一致，但之后不是直接将可回收对象进行清理，而是让存活对象向一端移动，然后直接清理边界以外的内存，因此可以避免不连续空间碎片的问题。 分代收集（Generational Collection）算法将内存划分为新生代及老年代，根据各年代的特点选用不同的垃圾收集算法。 Ⅱ. 几种垃圾收集器介绍 Serial收集器“单线程”垃圾收集器，应用于新生代。在进行垃圾收集时，会“Stop The World”，暂停其他工作线程。体验很差。但胜在简单高效。 ParNewSerial的多线程版本，仍然有“Stop The World”的问题。 Parallel Scavenge新生代收集器，使用复制算法。此垃圾收集器的目的是达到可控的吞吐量（Throughput），因此也被叫做“吞吐量优先”垃圾收集器。现在的虚拟机会进行自适应的调节策略——根据系统运行情况，动态调节参数以提供最合适的停顿时间或者最大的吞吐量。 Serial OldSerial的老年代版本，使用“标记-整理”算法。在CMS收集器在并发手机发生“Concurrent Mode Failure”时会使用Serial Old来进行垃圾收集。 Parallel OldParallel Scavenge收集器的老年代版本，使用多线程以及“标记-整理”算法。 CMSCMS（Concurrent Mark Sweep）收集器是以获得系统最短的回收停顿时间为目标的垃圾收集器。对于注重用户体验的系统，应用得十分广泛。从名字上就可以看到，CMS收集器使用了“标记-清除”算法的，其垃圾收集过程有四个阶段：1. 初始标记 2. 并发标记 3. 重新标记 4. 并发清除。其中初始标记、重新标记仍然会“Stop The World”。初始标记知识标记GC Roots能直接关联到的对象，速度很快；并发标记就是进行GC Roots Tracing的过程；重新标记是为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，此阶段停顿时间比初始标记要稍长，但比并发标记要短的多。但因为并发标记和并发清除两个阶段都允许收集器线程与用户线程一起工作，因此说CMS收集器是“并发”的。但CMS收集器也存在明显的缺点：1.对CPU资源很敏感，默认启动的线程数是（CPU数量+3）/4，当CPU在4个以上时，并发回收时垃圾收集线程会占用不少于25%的CPU资源，并随着CPU数量增加而下降，但当CPU数目不足4个时，会占用较多的CPU资源；2.因CMS收集器在并发清理时用户线程还在继续工作，因此CMS收集器无法处理浮动垃圾，可能出现“Concurrent Mode Failure”失败而导致Full GC；3.会产生大量空间碎片。但虚拟机可以设置参数，让CMS收集器在Full GC前进行内存碎片的合并整理。 G1收集器被称为当今收集器技术发展的最前沿成果之一，与其他收集器相比，它有以下特点：1.并行与并发：使用多CPU来缩短停顿时间2.分代收集3.空间整合4.可预测的停顿G1收集器收集的范围是整个堆，而不局限于新生代或者老年代。G1将整个堆划分为多个大小相等的独立区域（Region），虽然还有新生代及老年代的概念，但新生代及老年代不是物理隔离了，它们都是一部分Region（不需要连续）的集合。 Ⅲ. 内存分配及回收策略对象优先在新生代的Eden区分配，当Eden区中没有足够空间进行分配时，虚拟机将进行一次Minor GC，如果在Minor GC后Eden区中有空间可以保证分配，那么对象仍分配到Eden区，否则将通过分配担保机制提前转移到老年代中。 “大对象”将直接进入老年代中，典型的大对象就是很长的字符串以及数组。虚拟机提供参数可以设置大于这个值的对象直接在老年代中分配。 另外，虚拟机使用了分代收集的策略，那么必然需要有一个“年龄”指标来判定这个对象因为“年龄”太大应该被转移到老年代中。实际中，虚拟机为每个对象都定义了一个对象年龄计数器。对象在Eden区中熬过一次Minor GC，那么它的年龄就会加一，当年龄超过一定阈值（默认15岁），就晋升到老年代中。 但虚拟机对于晋升老年代也不是完全死板地按照年龄来判定，虚拟机有一个动态年龄判定的准则——当Survivor空间中相同年龄的所有对象大小之和大于Survivor空间一半，年龄大于等于该年龄的对象就会直接晋升到老年代中。 在Minor GC前，虚拟机会检查老年代中最大可用的连续空间是否大于新生代所有对象总空间，若检查成立，那么Minor GC必然是安全的。否则，便存在内存分配上的隐患，虚拟机中有一个参数定义是否允许担保失败。如果允许担保失败，那么会检查老年代最大可用的连续空间是否大于历代晋升到老年代对象的平均大小，如果大于，则尝试性进行一次Minor GC；如果小于，或者不允许担保失败，则进行一次Full GC。 简单介绍结束～]]></content>
      <tags>
        <tag>GC</tag>
        <tag>垃圾收集器</tag>
        <tag>内存分配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存区域与GC简介]]></title>
    <url>%2F2019%2F03%2F03%2FJVMMemoryIntro%2F</url>
    <content type="text"><![CDATA[介绍本次博文分为以下几块：1. 介绍下JVM内存区域的分区，以及各自区域的作用 2. 介绍下垃圾收集与对象回收相关的概念。本次博文只讲一些原理性的——或者说粗浅的JVM知识。试图用最简单易懂的语言讲清楚JVM的一些知识。下一篇会讲下GC的算法及各种垃圾收集器 Ⅰ. JVM内存区域JVM运行时数据区主要分为以下几块： 程序计数器 当前线程所执行的字节码的行指示器。此区域线程私有。 虚拟机栈 描述Java方法执行的内存模型，线程私有。虚拟机栈中的局部变量表存放着8种基本数据类型（boolean、byte等）、对象引用类型。 本地方法栈 与虚拟机栈作用类似。区别是虚拟机栈为虚拟机执行的Java方法（即字节码）服务，本地方法栈为Native方法服务。 堆 JVM管理内存中最大的一块，此区域被所有线程共享，作用是存放对象实例。Java堆是垃圾收集器（GC）管理的主要区域。 方法区 被各线程共享。存储已被虚拟机加载的类信息、常量、静态变量等数据。运行时常量池是方法区的一部分，主要存放编译期间生成的各种字面量和符号引用。这个区域的GC目标主要是常量池的回收和对类型的卸载。 Ⅱ. 垃圾收集与对象回收垃圾收集器回收的是哪些“不存活”的对象，那么如何判定对象“已死”？ 判断对象存活的算法1.1 引用计数法为对象添加一个引用计数器，当有地方引用此对象时，计数器加一，引用失效时减一，当引用计数为0的对象就被认为是应该被回收的。此算法实现简单，但有致命缺点——当两个对象循环引用时，尽管这两个对象没有其他作用，应该被判定为“死亡”，但在引用计数法中这样的对象是被判别为“存活”的。1.2 可达性分析法Java中实际是通过可达性分析来判定对象是否存活的。通过一系列的称为“GC Roots”的对象作为起点，从这些节点向下搜索，搜索走过的路径称为引用链，当一个对象到GC Roots没有任何引用链时，就判定这个对象不可达，从而是可以被回收的。Java中，可作为GC Roots的对象有以下几种： 虚拟机栈中引用的对象 方法区中类静态变量引用的对象 方法区中常量引用的对象 本地方法栈中JNI(Native方法)引用的对象 Java中引用的类型：Java中将引用分为以下四种：强引用，软引用，弱引用和虚引用。引用强度依次减弱。 强引用：只要对象是强引用，垃圾收集器宁愿OOM也永远不会回收这类对象。类似“new Object()”这样的就是强引用 软引用：软引用关联着的对象，在系统内存溢出前会将这些对象的内存进行回收 弱引用：被弱引用关联的对象只能生存到下一次GC前 虚引用：最弱的引用关系，对象是否有虚引用不会对其生存时间构成影响。设置虚引用唯一目的是在对象被回收时可以得到一个系统通知 对象的回收当对象被认为是可回收时，并不会立即回收。对象真正的“消亡”至少要经历两次标记：当对对象进行可达性分析发现不存在引用链时，对象将被第一次标记并且进行一次筛选，筛选的条件是对象是否有必要执行finalize()方法，如果对象被判定为有必要执行finalize()，那么对象会被放置在一个名为”F-Quene”的队列中，随后会有一个线程去执行。在执行finalize()时对象有一次拯救自己的机会——只要重新与引用链上任何一个对象建立关联即可。这样在GC进行第二次标记时，这个对象就会被移出队列。 下一章我们会讲下GC的各种算法、各种垃圾收集器以及内存分配相关的知识～]]></content>
      <tags>
        <tag>JVM</tag>
        <tag>内存</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式（五）——单例模式的多种实现方式]]></title>
    <url>%2F2019%2F02%2F23%2FsingletonDesignPattern%2F</url>
    <content type="text"><![CDATA[背景单例模式指某个类采用单例模式后，在这个类被创建后，只产生一个实例以供外部访问，且提供一个全局的访问点。 单例模式在开发中具有相当大的重要性，并且代码实现相对简洁。所以其是为数不多的在面试中会被问到且要求手撸代码的设计模式哦。 那么单例模式都有什么用处？有些时候，我们只需要一个对象，并不需要“new”出多个来使用，比如说线程池等，这个时候就必须要用到单例模式了。 设计方案单例模式有多种写法，并且存在几种不太合适的写法，接下来我们就来看下～ 所谓的“饱汉”模式 12345678910public class Singleton1 &#123; private static Singleton1 instance; public static Singleton1 getInstance() &#123; if (instance == null) &#123; instance = new Singleton1(); &#125; return instance; &#125;&#125; 这种模式下，可以做到延迟化加载，但是在多线程模式下会产生多个实例，可不就是很“饱”么？此模式非线程安全，不推荐使用。 “饱汉”模式优化 上面说了“饱汉”模式非线程安全，那么是否可以对此优化呢？ 12345678910public class Singleton2 &#123; private static Singleton2 instance; public static synchronized Singleton2 getInstance() &#123; if (instance == null) &#123; instance = new Singleton2(); &#125; return instance; &#125;&#125; 此模式通过增加synchronized关键字到getInstance方法中，看似解决了线程的安全问题，但是同步粒度太大，效率十分低下，不建议使用。 所谓的“饿汉”模式 那么如果考虑了性能，我们可以怎么做呢？ 1234567public class Singleton3 &#123; private static final Singleton3 instance = new Singleton3(); public static Singleton3 getInstance() &#123; return instance; &#125;&#125; 上面的这种方案通过不使用延迟加载来对上述问题作出优化，做到了线程安全。这样带来的问题就是在JVM加载Singleton3类时就会创建此类的唯一单例。如果Singleton3类需要耗费大量资源初始化，但又一直没有被使用，拿这就是一种极其浪费资源的行为了，也不建议使用。 双重检查锁（Double-checked Locking）改善同步带来的性能问题 12345678910111213public class Singleton4 &#123; private volatile static Singleton4 instance; public static Singleton4 getInstance() &#123; if (instance == null) &#123; synchronized (Singleton4.class) &#123; if (instance == null) instance = new Singleton4(); &#125; &#125; return instance; &#125;&#125; 这种模式将与第二种单例的模式有点类似，减少了同步的开销。相对来说是一个合理的单例写法。 DCL唯一的问题是在JDK版本小于1.5时会有DCL失效的问题。 我们知道类的实例化并不是一个简单的操作，内部其实主要包含了以下步骤：分配内存，初始化，实例指向内存。 那么当我们在进入第二个(instance 1234567891011121314151617在JDK1.5的版本中具体化了**volatile关键字**，将其加在对象前就可以保证每次都是从主内存中读取对象，从而修复了上述DCL所说的失效问题。因此DCL方式也是推荐的一种单例实现方式。5. 静态内部类生成单例```Javapublic class Singleton5 &#123; // 静态内部类 private static class GetInstance &#123; private static final Singleton5 INSTANCE = new Singleton5(); &#125; public static final Singleton5 getInstance() &#123; return GetInstance.INSTANCE; &#125;&#125; 此模式是单例模式的一种比较完美的实现。此模式起到了延时加载的作用，只有显示调用getInstance方法时，才会显示装载GetInstance类，从而实例化INSTANCE。此方法线程安全，推荐使用。 通过枚举生成单例 123public enum Singleton6 &#123; INSTANCE;&#125; 这是一种极其简单的生成单例的方式，简直有点颠覆我们正常的想象！我们可以通过Singleton6.INSTANCE来获取单例。此方法无偿提供了序列化机制，绝对防止多次实例化，及时面对复杂的序列化或者反射攻击，可以保证实例的线程安全。单元素枚举类型已经成为实现Singleton的最佳方法（但是博主也没有在实际开发中这么去实现过，下次一定得试试）。 另外，关于枚举，我们可以给出以下两点小tips： 枚举类实现其实省略了private类型的构造函数 枚举类的域(此例当中的INSTANCE)其实是相应的enum类型的一个实例对象 在枚举中我们构造方法限制为私有，在我们访问枚举实例时会执行构造方法，同时每个枚举实例都是static final类型的，也就表明只能被实例化一次。 关于枚举创建单例的相关知识，推荐一篇博客： Java 利用枚举实现单例模式 总结一般还是建议通过使用静态内部类和枚举的方式来生成单例的～]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>单例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式（四）——工厂模式]]></title>
    <url>%2F2019%2F02%2F05%2FfactoryDesignPattern%2F</url>
    <content type="text"><![CDATA[背景距离开办“糟糕”咖啡店已经有半年，凭借着高质量的咖啡豆、网红的店内装修以及贴心的服务，老三大获成功。但是我们知道，咖啡店一般都在中午之后才开业，于是早上阶段咖啡店是空闲的，因此具有商业头脑的老三联系了在乡下空闲的弟弟凯奇，想让凯奇和他婆娘来城里开办早餐店——在咖啡店卖早餐。凯奇和婆娘一合计，觉得这方案可行，就准备来咖啡店卖早餐了——主打烧饼！老三身为哥哥，那必须要帮衬下弟弟。凯奇的婆娘会做各种类型的烧饼——牛肉烧饼，猪肉烧饼，菜烧饼，土猪肉烧饼等。于是，早餐店的点餐系统又难住了老三。 方案设计 当客户准备点牛肉烧饼，就需要点餐系统通知凯奇现做一个牛肉烧饼，当客户需要点一个土猪肉烧饼时，凯奇就会去做一个土猪肉烧饼。最简单的点单系统的设计方案是“new”。是的，根据不同类型的馅料，“new”出来不同的烧饼。直觉上，老三觉得这种方案有点不对劲。他仔细一想就明白了这种“不对劲”在什么地方——当需要增加或者减少一种烧饼口味时，毫无疑问是需要修改点单系统的，这种针对“实现”进行编程的方案对代码的侵入是很强的，并且也增加了系统的耦合。那么怎么将实例化具体类的代码从应用中抽离，从而不对系统其他部分产生影响呢？ 另外，凯奇的野心可是很大的，他还准备开加盟店呢。那这样又带来一个问题，同样的牛肉烧饼，江浙口味和西安口味可能有所区别，如何能让加盟店产生区域化的特色又不破坏烧饼本身的共性呢？ 架构师Juns提出了一种方案：工厂模式。 那么，工厂模式是什么？ 工厂模式定义了一个创建对象的接口，可以由子类决定需要实例化哪一个类。 工厂模式的类图如下： // 此处应有类图 工厂模式中包含以下几种角色： 1. 抽象创建者：定义了一个抽象的工厂方法，通常包含依赖于抽象产品的相关代码 1. 具体创建者：实现了抽象创建者的接口，负责具体的产品对象的创建 3. 抽象产品类：是具体产品对象的基类 4. 具体产品类：实现了抽象产品类接口，每一个具体产品类都会对应一个工厂 设计方案针对上面介绍的工厂模式，我们来设计下方案吧 首先公共的抽象烧饼Pancake 1234567891011121314151617181920212223242526public abstract class Pancake &#123; /** * 烧饼名字 */ private String name; /** * 烧饼馅料 */ private String stuffing; /** * 烧饼口味：辣等 */ private String flavour; public Pancake(String name, String stuffing, String flavour) &#123; this.name = name; this.stuffing = stuffing; this.flavour = flavour; &#125; void pancakesType() &#123; System.out.println("pancakes name: " + name); System.out.println("pancakes stuffing: " + stuffing); System.out.println("pancakes flavour: " + flavour); &#125;&#125; 建立抽象的创建者——烧饼加盟店 1234public abstract class PancakeStore &#123; abstract Pancake createPancake(String type);&#125; PancakeStore是一个抽象类，其中有一个抽象的方法createPancake，这就可以允许子类在继承时创建符合加盟店区域特色的烧饼了！ 建立具体的烧饼类——江浙口味的牛肉和猪肉烧饼以及四川口味的牛肉和猪肉烧饼 123456789101112131415161718192021public class ZJBeefPancake extends Pancake &#123; private static String name = "zjBeefPancakes"; private static String stuffing = "beef"; private static String flavour = "salt"; public ZJBeefPancake() &#123; super(name, stuffing, flavour); &#125; public static String getName() &#123; return name; &#125; public static String getStuffing() &#123; return stuffing; &#125; public static String getFlavour() &#123; return flavour; &#125;&#125; 123456789101112131415161718192021public class ZJPorkPancake extends Pancake &#123; private static String name = "zjPorkPancakes"; private static String stuffing = "pork"; private static String flavour = "salt"; public ZJPorkPancake() &#123; super(name, stuffing, flavour); &#125; public static String getName() &#123; return name; &#125; public static String getStuffing() &#123; return stuffing; &#125; public static String getFlavour() &#123; return flavour; &#125;&#125; 123456789101112131415161718192021public class SCBeefPancake extends Pancake &#123; private static String name = "scBeefPancakes"; private static String stuffing = "beef"; private static String flavour = "hot"; public SCBeefPancake() &#123; super(name, stuffing, flavour); &#125; public static String getName() &#123; return name; &#125; public static String getStuffing() &#123; return stuffing; &#125; public static String getFlavour() &#123; return flavour; &#125;&#125; 123456789101112131415161718192021public class SCPorkPancake extends Pancake &#123; private static String name = "scPorkPancakes"; private static String stuffing = "pork"; private static String flavour = "hot"; public SCPorkPancake() &#123; super(name, stuffing, flavour); &#125; public static String getName() &#123; return name; &#125; public static String getStuffing() &#123; return stuffing; &#125; public static String getFlavour() &#123; return flavour; &#125;&#125; 建立具体的创建者——烧饼加盟店，分别江浙和四川区域的加盟店 在这之前我们先建立一个枚举来定义牛肉和猪肉等烧饼馅料吧！ 123456789101112131415161718192021public enum PancakeEnum &#123; BEEF_PANCAKE(0, "beef"), PORK_PANCAKE(1, "pork"); private Integer code; private String type; PancakeEnum(Integer code, String type) &#123; this.code = code; this.type = type; &#125; public Integer getCode() &#123; return code; &#125; public String getType() &#123; return type; &#125;&#125; 现在来建立区域加盟店吧！ 12345678910111213141516public class ZJPancakeStore extends PancakeStore &#123; @Override public Pancake createPancake(String type) &#123; if (StringUtils.isEmpty(type)) &#123; System.out.println("type is illegal!"); return null; &#125; if (BEEF_PANCAKE.getType().equals(type)) &#123; return new SCBeefPancake(); &#125; else if (PORK_PANCAKE.getType().equals(type)) &#123; return new SCPorkPancake(); &#125; return null; &#125;&#125; 12345678910111213141516public class SCPancakeStore extends PancakeStore &#123; @Override Pancake createPancake(String type) &#123; if (StringUtils.isEmpty(type)) &#123; System.out.println("type is illegal!"); return null; &#125; if (BEEF_PANCAKE.getType().equals(type)) &#123; return new SCBeefPancake(); &#125; else if (PORK_PANCAKE.getType().equals(type)) &#123; return new SCPorkPancake(); &#125; return null; &#125;&#125; 来，点个烧饼吧！ 123456789101112131415public class PancakeOrderClient &#123; public static void main(String[] args) &#123; PancakeStore scPancakeStore = new SCPancakeStore(); PancakeStore zjPancakeStore = new ZJPancakeStore(); Pancake pancake = scPancakeStore.createPancake(BEEF_PANCAKE.getType()); pancake.pancakesType(); System.out.println("***********************"); pancake = zjPancakeStore.createPancake(PORK_PANCAKE.getType()); pancake.pancakesType(); &#125;&#125; 看下结果吧！ 123456789pancakes name: scBeefPancakespancakes stuffing: beefpancakes flavour: hot***********************pancakes name: scPorkPancakespancakes stuffing: porkpancakes flavour: hotProcess finished with exit code 0 总结上面讲的是普通的工厂模式，另外还有一种设计模式名为“抽象工厂”，抽象工厂模式提供一个接口，用于创建相关或依赖对象的家族。抽象工厂与工厂模式的主要区别是抽象工厂提供了一个用来创建一个产品家族的抽象类型，抽象工厂集合了一群相关的产品。举个例子，如果凯奇的加盟店烧饼还需要控制原材料的渠道，比如说面粉、芝麻等，就可以使用抽象工厂模式了。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>工厂模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式（三）——装饰者模式]]></title>
    <url>%2F2019%2F01%2F26%2FdecoratorDesignPattern%2F</url>
    <content type="text"><![CDATA[背景老三最近做了一个创业项目——“糟糕”咖啡店。做的还挺不错，因此咖啡店最近要更新他们的菜单，增加很多种饮品。比如奶茶，咖啡，果汁。我们知道咖啡可以有很多种，比如拿铁、摩卡、卡布奇诺等。并且还可以为不同的咖啡根据用户的需求加入不同的调料，比如奶泡、巧克力、香草、奶油等。“糟糕”咖啡店最原始的点单系统，是CEO兼CTO老三自己搞定的。老三也是一个有着最基本“OO”素养的程序员。因此他在最开始时为所有的饮品都建立了一个抽象接口：Beverage。LatteCoffee、Espresso、OrangeJuice等饮品都实现了Beverage这个抽象接口。而当菜单迎来新的一轮变革时，老三犯难了。 方案设计 当用户确定了需要的饮料后，点单系统必须计算出用户所需要支付的价钱。最简单的莫过于，将所有可能存在的饮料搭配都独立为一个类，那这样就可以根据具体的饮料种类去选择类，从而计算出价钱了。理想很丰满，现实却很骨感。老三懵逼地发现自己需要同时维护所有的类——当奶泡价格改变时，改变的不仅仅是一个类，而是所有涉及到“奶泡”的类！系统的耦合太严重，违反了“对扩展开放，对修改关闭”的设计原则。 老三是个爱思考的程序员，仔细一想，其中必有蹊跷——一定有更方便快捷，更“程序员”的思路来完成这个项目。 那么是什么呢？ 在现有的知识下，老三想到可以用基类继承的方法来优化这个项目架构： 首先建立Beverage的基类，将各种“加料”作为基类的成员变量，然后让子类在继承时去计算饮料的价格。这样可以在很大程度上改变之前方案带来的问题。但是老三摸摸下巴，发现事情没那么简单。如果要添加新的调料，那就需要改动基类，另外对于“茶饮料”，成员变量中含有“摩卡”之类的调料无疑是不太合适的。再者，如果客户想要加双份的奶泡呢？思考到这些，让老三本就不多的头发预发稀少。。。 “伪资深开发工程师”李五建议老三可以使用“装饰者模式”来解决这个难题。即用饮料为主题，然后在运行时加上调料来“装饰”（decorate）饮料。 装饰者模式的类图如下： // 此处应有类图 装饰者模式中包含以下几种角色： 1. 抽象组件类：装饰对象和被装饰对象有相同的接口（当然也可以是抽象类）。这样客户端对象就能以和真实对象相同的方式和装饰对象交互。 2. 具体被装饰者：装饰对象接受所有来自客户端的请求。它把这些请求转发给真实的对象。 3. 抽象装饰者：实现了抽象组件类，所有的装饰者都继承至这一抽象类。 3. 具体装饰者：继承至抽象装饰者，装饰对象包含一个被装饰者对象的引用（reference）。装饰对象接受所有来自客户端的请求。它把这些请求转发给真实的对象。 装饰对象可以在转发这些请求以前或以后增加一些附加功能。这样就确保了在运行时，不用修改给定对象的结构就可以在外部增加附加的功能。在面向对象的设计中，通常是通过继承来实现对给定类的功能扩展。 设计方案装饰者模式可以动态地将功能附加到对象上。根据上述例子，建立一个公共的抽象类Beverage，然后coffee类继承Beverage类作为被装饰者类；然后建立一个CondimentDecorator类作为抽象的装饰者类，也继承Beverage类，其他具体的装饰者则都继承这个抽象的装饰者类，并且每一个具体的装饰者中都有一个被装饰者对象的引用 首先公共的抽象Beverage类 123456789public abstract class Beverage &#123; private String desc = "no Beverage"; public String getDesc() &#123; return desc; &#125; public abstract double cost();&#125; 12 建立抽象的装饰者类 123public abstract class CondimentDecorator extends Beverage &#123; public abstract String getDesc();&#125; 建立Coffee类，继承至Beverage类 123456789101112public class Coffee extends Beverage &#123; private String desc; public Coffee() &#123; desc = "Original coffee"; &#125; @Override public double cost() &#123; return 0.99; &#125;&#125; 建立一个“抹茶”（Mocha）的装饰者类，继承至CondimentDecorator 1234567891011121314151617public class Mocha extends CondimentDecorator &#123; private Beverage beverage; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public String getDesc() &#123; return beverage.getDesc() + ", add Mocha!"; &#125; @Override public double cost() &#123; return 0.2 + beverage.cost(); &#125;&#125; 建立一个“牛奶”（Milk）的装饰者类，继承至CondimentDecorator 1234567891011121314151617public class Milk extends CondimentDecorator &#123; private Beverage beverage; public Milk(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public String getDesc() &#123; return beverage.getDesc() + ", add Milk!"; &#125; @Override public double cost() &#123; return 0.3 + beverage.cost(); &#125;&#125; 做个实验，点一杯咖啡，再添加一些调料吧！ 1234567891011121314public class CoffeeOrder &#123; public static void main(String[] args) &#123; Beverage beverage = new Coffee(); System.out.println("beverage: " + beverage.getDesc() + " $" + beverage.cost()); Beverage beverage1 = new Milk(beverage); System.out.println("beverage: " + beverage1.getDesc() + " $" + beverage1.cost()); Beverage beverage2 = new Mocha(beverage1); System.out.println("beverage: " + beverage2.getDesc() + " $" + beverage2.cost()); &#125;&#125; 实验结果 12345beverage: no Beverage $0.99beverage: no Beverage, add Milk! $1.29beverage: no Beverage, add Milk!, add Mocha! $1.49Process finished with exit code 0 总结就是上面这样了～又利用设计模式解决了一个比较棘手的问题哦]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>装饰者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高可用服务策略——限流及降级]]></title>
    <url>%2F2019%2F01%2F01%2FHighAvailability%2F</url>
    <content type="text"><![CDATA[介绍为了提供高可用的服务。很重要的两个策略是——限流、降级。限流就是防止过多的恶意请求流量以及防止流量超出系统能承载的阈值。限流也分几个维度：页面层、接入层、应用层。另外一个重要的策略是设计降级开关，对业务、服务等进行降级。 Ⅰ. 限流限流是一种通过限制并发以及请求数量来保证系统高可用的一种手段。当达到限流阈值时，可以通过拒绝服务（直接引导到错误页面或出现“购物车开小差了哦”这样的提示），等待（典型的就是秒杀系统），降级（返回兜底数据或对于某些弱依赖不进行展示，如相似商品推荐等）等策略来保证服务可用——至少是部分可用。限流的阈值我们一般是通过压测时服务的性能来决定的，压测能大致得到系统处理的峰值，可以根据峰值来确定系统的限流阈值。常用的限流方法有以下几种：1.原子计数器。通过对一定时间内，访问接口或服务的次数来进行限流。2.令牌桶限流算法。3.漏桶算法限流。对于应用级限流，可以通过线程池等技术来限制使用资源的数目，也可以对某个接口的并发数或总请求数进行限制。 Ⅱ. 降级降级的作用是保证核心服务可用——为此可以牺牲一些弱依赖服务。比如在查看购物车列表这个服务中，购物车列表的显示是最核心的，而另外如促销显示、相似推荐等服务并不是核心的，如果遇到购物车列表访问量太高，就可以通过取消调用弱依赖服务的策略来保证核心的购物车列表显示服务可用。配置降级预案之前要对应用进行梳理，根据服务调用链路来看哪些服务属于弱依赖，需要降级。以下简单介绍几种降级的方案： 服务降级：对于服务调用链路中属于弱依赖的服务进行降级。比如购物车列表的相似推荐等。 读降级：当后端服务出现问题时，可以通过读缓存的方式来降级。如商品详情页的库存。 写降级：为了避免频繁对db进行写入。比如秒杀时，可以先只对缓存进行更新，而后用异步队列扣减db的库存，保证最终一致性。 风控降级：在大促时，对一些高风险的用户——比如说访问流量非常多，同一ip地址登入等行为进行降级。使这部分用户不影响应用稳定性。 页面降级：比如某些页面调用的一些服务异常，可以将这些页面或者部分页面进行降级。 降级一般分为自动降级及人工降级。自动降级可以考虑通过考虑以下几种指标来配置：1. 服务超时时间及超时重试次数；2. 服务调用失败次数，失败达到阈值则进行熔断，熔断后需要通过异步线程定时探测服务是否恢复，恢复了则取消降级；3. 故障，比如网络故障，socket异常。降级后可以显示兜底数据、缓存数据或默认数据；4. 限流，当服务到达限流阈值时，可以进行降级，如提示购物车开小差了等。人工降级较为灵活，但需要做好应用服务等预警。]]></content>
      <tags>
        <tag>高可用</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大型互联网架构演进]]></title>
    <url>%2F2018%2F12%2F30%2FinternetArchitechture%2F</url>
    <content type="text"><![CDATA[背景最近看了两本书——《企业it架构转型之道》和《亿级流量网站架构核心技术》。之前就对网站架构比较感兴趣，看完以后收获颇丰，《企业it架构转型之道》一书因为作者的遣词用句我实在无力吐槽，有些内容也觉得侃侃而谈的成分高于干货，随便过了一遍。相比之下，《亿级流量网站架构核心技术》这本书就很接地气了，扎根于实战经验，介绍了很多现行有效的架构方案，让我收益非常。因此，在看完以后，博主也试着总结了下一般互联网架构的演进及发展思路。 方案设计###初期：“一体化”，大而杂访问量很低，前端页面+后端应用+数据库都在一台机器上，且后端服务都是单点（非分布式集群）的。这时一整个系统都部署在一台服务器上，当发布时就无法访问，不过因为流量少，大家也不关心访问体验。 ###发展1: 应用集群部署当流量开始增加，并且我们在上面说了，如果所有的应用层都只是单点部署的话，就会出现在发布时完全无法正常访问页面的情况。这个时候就可以使用分布式集群部署，即把系统部署在多台机器上。当用户在请求时，会通过类似Nginx负载均衡的方式，将请求分发到集群中的某个服务节点上，这样的好处一是通过多台机器部署可以让系统扛住更多的流量，二是因为采用集群部署，在发布时是一台一台机器发布的，因此不会出现系统停止正常服务的情况，这样就带来更好的用户体验。那么当流量再次增多呢，这时候该怎么办？可以进行分布式集群扩容——再次增加机器。但是，随着流量的再度增加，难道需要无休止的集群扩容么？集群扩容带来的成本与收益能否满足符合我们的预期呢？这也是接下来要考虑的问题。 ###发展2：应用拆分当系统做大以后，必然存在相当多的模块，以电商系统为例。基本的电商系统存在以下模块：商品、店铺、交易、物流等。这个时候如果各个模块还统一部署在同一台服务器上，这时必会带来一个问题：一个交易模块的需求发布会导致整个系统的发布，模块系统之间存在严重的耦合。为了解决这个问题，可以对系统进行拆分。拆分的维度可以分成以下几种： 系统功能维度：按照系统功能或者具体的业务进行拆分，比如商品系统、交易系统、物流系统等。因为不同的系统负责的业务可能千差万别，让不同的团队维护不同的系统模块，这样的架构也将大大减轻工程师的压力，也有助于各个系统的特性发展； 功能维度：这是维度更加细致的一种拆分。当系统发展到了一种程度后，即使是一个子系统所承载的业务也会变得十分复杂。因此，此时要对一个子系统的具体功能进行拆分，比如交易系统可以按照功能拆分为购物车模块、下单模块、结算模块、售后模块、维权模块等。这个时期可以考虑将应用服务化，搭建分布式的服务。比如使用dubbo进行服务自动注册和发现，另外还要考虑服务分组和隔离； 应用层维度：按照前后端、数据层进行拆分。当前后端没有隔离时，前后端的发布将互相影响，并且后端服务器宕机时将导致前端页面都无法展示，这就导致了整体的访问体验不太好。另外，当有过多IO密集型的请求就会导致系统无法正常提供其他的服务，从而出现卡顿，超时等异常情况。这个时候将应用层与数据层进行分离，可以在一定的程度上减缓服务器处理的压力。 ###发展3：缓存根据28原则（80%的请求落在20%的数据上），必然会存在热点数据。而且随着访问量的增加，很多用户的访问数据都是差不多的，或者说有的访问数据对于时效性要求不太高（比如电商网站，对于商品详情页以及库存的访问就是这样的一种热点数据）。想象一下如果很多用户都在访问一个商品的详情页，如果都走db，对db的压力是相当大的，此时如果db宕机了，整个网站都将奔溃。这时候就可以利用缓存技术来解决热点数据的问题。缓存在很多时候对于读服务都被认为是抗流量的“银弹”。缓存也分本地缓存以及分布式缓存。本地缓存可以使用单机redis来实现，分布式缓存可以通过集群的redis来实现。另外还有CDN缓存，对一些静态的数据如商品详情页图片等通过CDN缓存来进行拉取 ###发展4: 数据库拆分、数据库读写分离、分库分表和数据异构在前面我们讲到了应用拆分，随之对应的，数据库也会按照应用进行垂直拆分。比如说电商系统的表拆分为商品表、订单表、用户表、售后表、物流表等。在前面的阶段，对应用进行分布式的部署，并且也为db增加了缓存。然而随着系统量级的增大，还是免不了增加对db进行读写。因此对于db来说，也需要一个能够扛住大量读写请求的方案。对于数据层，首先可以使用主从模式对db的读写进行分离——某一台mysql服务器作为master，另外几台作为slave。slave机器只供读服务使用，写服务则写入master后同步到各个slave，以尽量保证数据一致性。因为对于db来说，80%以上的请求都是读的，因此读写分离的数据架构可以极大增强数据库的性能。随着流量和数据量的进一步提升，单库单表的数据架构会带来容量及I/O的瓶颈，此时的查询性能将会收到影响。此时可以通过分库分表的策略来解决。分库分表是一种对数据进行水平拆分的方案。一般按照用户ID，订单号等维度进行数据等拆分，一般的拆分库表的算法有取模、哈希等。对于订单的分库分表，一般是按照订单号来进行拆分的，如果我们要查询某个用户的订单列表，这个时候就要聚合多张表的数据，此时的性能是极其低下的。为了应对这种情况，此时需要对订单表进行异构，按照用户ID进行分库分表，生成一张用户订单表。这样就会提高查询的效率。 总结至此，本文到这也就结束了。本文讲述了一般的互联网架构的演进方案。架构是根据业务需求不断完善演进的，要根据不同的业务特性作出不同的方案设计，本文只是总结了一些常用的一些技术和手段。并且《亿级流量网站架构核心技术》一书中介绍的内容远不止这些，而且有些内容是真的在工作中帮到了博主，有时间会继续介绍下相关知识的～哦，另外，本来应该配图的，但是现在七牛云这个坑货，把我的图床链接干掉了，我也懒得去实名认证，博客中的图片一直没办法显示，之后等我不那么咸鱼了再去处理吧。。懒。。]]></content>
      <tags>
        <tag>架构</tag>
        <tag>互联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastJson解析时抛异常：com.alibaba.fastjson.JSONException:create instance error]]></title>
    <url>%2F2018%2F12%2F21%2FjsonException%2F</url>
    <content type="text"><![CDATA[背景最近对接一个物流公司的“查询物流走件详情”的接口，对方会返回json格式的字符串。那么我就需要对字符串进行json反序列化。根据物流公司给出的对象结构，我在解析的类中建立了相应的物流详情对象的内部类，然后使用fastjson对物流公司返回的字符串信息进行反序列化。然而，异常发生了 问题与原因###先看代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class ParseTraceDetails &#123; public static void main(String[] args) &#123; String msg = "msg: &#123;\"action\":\"签收\",\"city\":\"杭州\",\"detailDesc\":\"已签收\",\"time\":\"2018-12-11 10:24:00\",\"weight\":2.5&#125;"; Trace trace = JSON.parseObject(msg, Trace.class); &#125; private class Trace &#123; /** * 操作时间，格式为 yyyy-MM-dd */ private String time; /** * 走件信息详情 */ private String detailDesc; /** * 事件/操作 */ private String action; /** * 当前城市 */ private String city; /** * 货物重量,单位(千克) */ private Double weight; public String getTime() &#123; return time; &#125; public void setTime(String time) &#123; this.time = time; &#125; public String getDetailDesc() &#123; return detailDesc; &#125; public void setDetailDesc(String detailDesc) &#123; this.detailDesc = detailDesc; &#125; public String getAction() &#123; return action; &#125; public void setAction(String action) &#123; this.action = action; &#125; public String getCity() &#123; return city; &#125; public void setCity(String city) &#123; this.city = city; &#125; public Double getWeight() &#123; return weight; &#125; public void setWeight(Double weight) &#123; this.weight = weight; &#125; &#125;&#125; 代码比较简单，在ParseTraceDetails类中建立了一个名为Trace的内部类，然后main方法中进行json反序列化，异常信息如下： 12345678910111213Exception in thread "main" com.alibaba.fastjson.JSONException: create instance error, class com.mogujie.tesla.benchmark.ParseTraceDetails$Trace at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.createInstance(JavaBeanDeserializer.java:164) at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:566) at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:188) at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.deserialze(JavaBeanDeserializer.java:184) at com.alibaba.fastjson.parser.DefaultJSONParser.parseObject(DefaultJSONParser.java:642) at com.alibaba.fastjson.JSON.parseObject(JSON.java:350) at com.alibaba.fastjson.JSON.parseObject(JSON.java:254) at com.alibaba.fastjson.JSON.parseObject(JSON.java:467) at com.mogujie.tesla.benchmark.ParseTraceDetails.main(ParseTraceDetails.java:15)Caused by: java.lang.NullPointerException at com.alibaba.fastjson.parser.deserializer.JavaBeanDeserializer.createInstance(JavaBeanDeserializer.java:111) ... 8 more 可以看到错误是“创建实例失败”，究竟为什么失败？ 其实这是Java内部类的实现机制造成的，内部类可以分为一般的内部类和静态的内部类（也叫嵌套类）。一般的内部类编译后有一个指向外部类的引用，因此内部类是强依赖外部类的实例的。如果使用内部类进行json序列化，会因为找不到它的外部类而无法生成实例，因此报了上述create instance error异常。而静态内部类因为是静态的，里面没有默认的外部类的引用，即使没有外部类的对象也能够使用，因此在json转换的时候是正常的。]]></content>
      <tags>
        <tag>异常</tag>
        <tag>fastjson</tag>
        <tag>exception</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Self-assessment Checklist of HSK]]></title>
    <url>%2F2018%2F12%2F08%2Fquestionnaire%2F</url>
    <content type="text"><![CDATA[Dear friends, I’m a postgraduate student of Renmin University of China, majoring in Teaching Chinese as a Second language, I’m doing a research about learner’s Chinese level, and need your help, please choose the questionnaire below which fits your Chinese level, and finish it, this will help me a lot, thank you very much! Self-assessment Checklist of HSK level 1 Self-assessment Checklist of HSK level 2 Self-assessment Checklist of HSK level 3 Self-assessment Checklist of HSK level 4 Self-assessment Checklist of HSK level 5 Self-assessment Checklist of HSK level 6]]></content>
      <tags>
        <tag>问卷</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式（二）——观察者模式]]></title>
    <url>%2F2018%2F12%2F01%2FobserverDesignPattern%2F</url>
    <content type="text"><![CDATA[背景尼古拉斯·赵四的同学本尼迪·李云在互联网气象站公司工作，最近他们公司要做一个气象监测的应用。这个应用需要能监控现在的天气状况，指标主要有以下三种：温度，湿度以及气压。并且应用有三块面板可以分别显示目前的天气状况、气象数据统计以及天气预报。当天气情况变化时，三块面板必须根据各自的指标实时更新。赵四拿到这个需求，并拿到了一个WeatherData对象，这个对象是气象站提供的，可以用来获取到温度，湿度以及气压三个指标（换而言之，他根不需要关注这三个指标是如何获取到的，只需要通过WeatherData对象的getter方法即可拿到对应指标的值）。另外，他也并不需要关注气象数据的统计算法以及天气预报的算法，这些算法都有现成的接口可以调用。因此，他拿到指标以后，他只需要将对应的值放到对应的面板上进行显示就好了。那么中间最重要的一步——面板如何感知到三个指标的变化并及时作出回应？ 方案设计 最简单的当然是党天气数据变化时，在WeatherData中分别调用三个面板的接口方法进行改变了。然而这种简单的做法也带来了一些不太好的影响——比如说破坏了WeatherData的封装；每一次删除或者增加一个面板时都会对WeatherData类进行操作，这种方式让面板对象与WeatherData对象的耦合太紧了……赵四为此头发都掉了1256根，人也日渐消瘦，公司的资深程序员里斯本·二狗子于心不忍，向赵四提出了一个建议，为什么不考虑考虑使用观察者模式呢？ 赵四一脸懵逼，很认真的向二狗子请教，什么是观察者模式？ 二狗子邪魅一笑，转身偷偷上谷歌，然后说道： 观察者模式又叫发布订阅模式，定义了对象间一对多的依赖关系。当一个对象状态发生变化，其他依赖于这个对象的依赖者们都会被通知，然后自动更新。举个栗子，当我们关注了某个人的博客（相当于订阅），当此博客有更新（发布了新文章），那么关注此博客的用户都会收到类似“您关注的博客有更新”这样的消息。诸如此类的模式就是观察者。 赵四一想，诶？这个模式听起来确实很符合现在的需求呀！ 赵四也上网继续搜索与策略模式相关的资料，发现了观察者模式的类图： // 本来有个类图的，然而坑爹的七牛云把我图床的测试域名回收了，接下来要想用就必须备案绑定了，慢慢来吧。。。懒 - - 1. 抽象主题：主题中包含了观察者的集合。并提供添加，删除以及通知观察者的接口 2. 具体主题对象：继承至抽象主题，用一个Vector存储观察者，内部维护了一个状态量，当状态发生改变，就向观察者进行通知。 3. 抽象观察者：内部有update方法。这是为主题发生改变时需要获得通知的对象所建立的一个更新接口 4. 具体观察者对象：实现了抽象观察者的接口 设计方案观察者模式定义了对象间一对多的依赖关系。WeatherData对象在这里就是“一”，而那些显示指标的面板就是“多”。回到上面赵四的疑问：如何感知到三个指标的变化并及时作出回应？从上面观察者模式的类图，如果把WeatherData对象当作主题，把三个面板当作观察者，面板要显示信息，就要向主题进行注册。那这样WeatherData对象就知道面板的存在了，那当天气指标变化时，WeatherData就可以调用面板的某个方法来通知面板观测值了。 首先构建WeatherData主题类 1234567891011121314151617181920212223242526272829public class WeatherData extends Observable &#123; private float temperature; private float humidity; private float pressure; public void measurementsChanged() &#123; setChanged(); notifyObservers(); &#125; public void setMeasurements(float temperature, float humidity, float pressure) &#123; this.temperature = temperature; this.humidity = humidity; this.pressure = pressure; measurementsChanged(); &#125; public float getTemperature() &#123; return temperature; &#125; public float getHumidity() &#123; return humidity; &#125; public float getPressure() &#123; return pressure; &#125;&#125; 可以看到WeatherData继承了Observable类，Observable是Java为观察者模式提供的抽象主题类（即Subject）。我们可以看到在measurementsChanged方法中调用了两个继承至Observable类的方法： setChanged()： 来看下setChanged方法的源码： 1234567/** * Marks this &lt;tt&gt;Observable&lt;/tt&gt; object as having been changed; the * &lt;tt&gt;hasChanged&lt;/tt&gt; method will now return &lt;tt&gt;true&lt;/tt&gt;. */ protected synchronized void setChanged() &#123; changed = true; &#125; setChanged方法很简单，就是将changed变量至为true（默认为false）。至于changed标志位有什么用，请看第二个方法。 notifyObservers()： 首先notifyObservers()内部调用了另一个重载的notifyObservers方法： 123public void notifyObservers() &#123; notifyObservers(null); &#125; 我们来看下真实的方法实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * If this object has changed, as indicated by the * &lt;code&gt;hasChanged&lt;/code&gt; method, then notify all of its observers * and then call the &lt;code&gt;clearChanged&lt;/code&gt; method to indicate * that this object has no longer changed. * &lt;p&gt; * Each observer has its &lt;code&gt;update&lt;/code&gt; method called with two * arguments: this observable object and the &lt;code&gt;arg&lt;/code&gt; argument. * * @param arg any object. * @see java.util.Observable#clearChanged() * @see java.util.Observable#hasChanged() * @see java.util.Observer#update(java.util.Observable, java.lang.Object) */ public void notifyObservers(Object arg) &#123; /* * a temporary array buffer, used as a snapshot of the state of * current Observers. */ Object[] arrLocal; synchronized (this) &#123; /* We don't want the Observer doing callbacks into * arbitrary code while holding its own Monitor. * The code where we extract each Observable from * the Vector and store the state of the Observer * needs synchronization, but notifying observers * does not (should not). The worst result of any * potential race-condition here is that: * 1) a newly-added Observer will miss a * notification in progress * 2) a recently unregistered Observer will be * wrongly notified when it doesn't care */ if (!changed) return; arrLocal = obs.toArray(); clearChanged(); &#125; for (int i = arrLocal.length-1; i&gt;=0; i--) ((Observer)arrLocal[i]).update(this, arg); &#125; 可以changed标志位置为true才可以在接下来的notifyObservers()方法中通知观察者进行更新。 可以看到，在遍历数组arrLocal通知观察者进行update操作的时候是不“同步的”，因此此方法也存在两个问题（如此段代码的注释）：1. 因为遍历观察者的方法不做同步，所以在同步方法后新加入的观察者，将会错过此次正在进行的通知 2. 同理，最近被删除的观察者也会被错误地通知。而此时，这个观察者已经不关注这个主题了。 面板显示的接口 123public interface DisplayPanel &#123; void display();&#125; DisplayPanel接口中只有一个方法，即用来显示一些数据。每个不同的面板都会实现这个接口。 实时天气面板实现 1234567891011121314151617181920212223242526272829public class WeatherCurrentDisplay implements Observer,DisplayPanel &#123; private Observable observable; private float temperature; private float humidity; private float pressure; public WeatherCurrentDisplay(Observable observable) &#123; this.observable = observable; observable.addObserver(this); &#125; @Override public void update(Observable obs, Object arg) &#123; if (obs instanceof WeatherData) &#123; WeatherData weatherData = (WeatherData) obs; this.temperature = weatherData.getTemperature(); this.humidity = weatherData.getHumidity(); this.pressure = weatherData.getPressure(); display(); &#125; &#125; @Override public void display() &#123; System.out.println("weather temperature:" + temperature + ", humidity:" + humidity + ", pressure:" + pressure); &#125;&#125; WeatherCurrentDisplay类不仅实现了DisplayPanel接口，还实现了Observer接口。与Observable类似，Observer接口同样是Java对观察者模式的支持。可以看到在WeatherCurrentDisplay的构造器中，将“主题”元素作为入参传入了观察者中，并调用主题的addObserver()方法，将WeatherCurrentDisplay对象注册到了主题中。另外，在上面的WeatherData类中我们调用了Observable的notifyObservers方法，内部就会对注册到主题内的观察者进行update()，而在WeatherCurrentDisplay类中便覆盖（override）了Observer接口的update()方法，具体的实现就是调用了display()方法，对改变的天气指标进行显示。 气象站的代码实现 123456789public class WeatherStation &#123; public static void main(String[] args) &#123; WeatherData weatherData = new WeatherData(); WeatherCurrentDisplay indexDisplay = new WeatherCurrentDisplay(weatherData); weatherData.setMeasurements(30,50, 1800); weatherData.setMeasurements(35,80, 2800); &#125;&#125; 结果显示 1234weather temperature:30.0, humidity:50.0, pressure:1800.0weather temperature:35.0, humidity:80.0, pressure:2800.0Process finished with exit code 0 总结 关于“观察者模式”的两种模式： 观察者模式在具体实现时，根据系统设计时的不同需求，一般有两个不同的版本：推和拉。推模式——就是当主题发生改变时，主题主动将变化的信息推送给观察者。比如说气象站只需要温度，湿度和气压三个指标，那么主题只将这三个观察者关注的指标推送出去。拉模式——当主题发生变化，仅仅只告诉观察者“主题发生变化”，若观察者想要知道具体的改变信息，需要主动从主题中“拉”出来。拉模式一般会把主题对象作为update()方法的入参，从而传递给观察者。当观察者需要获取具体变化信息时，可以通过主题对象的引用来获取。很明显，上面赵四实现的代码就使用了拉模式。 那么推和拉模式有什么区别呢？ 推模式将改变信息作为update方法的入参，所以如果我们要增加给观察者的信息时，要么提供新的update方法或者重新实现观察者，这样的情况是不易于扩展的；而拉模型将主题对象自身传递给观察者，让观察者自己去按需要取得信息，这样就不存在上述的问题。 当我们明确知道需要通知的信息时，我们可以使用推模式。而当我们不清楚观察者具体需要的信息时，可以使用拉模式。 使用Java自带的观察者模式有以下几个问题： 因为遍历观察者的方法不做同步，所以在同步方法后新加入的观察者，将会错过此次正在进行的通知。 同理，最近被删除的观察者也会被错误地通知。而此时，这个观察者已经不关注这个主题了。 不能依赖观察者被通知的次序。可以从源码中看到主题通知观察者的顺序是按照list倒序的，所以当代码以来通知顺序的时候，使用就需要很小心了。当然可以通过自己写主题及观察者的代码避免这种情况，也不复杂。 另外，我们必须继承Observable类，才能用到setChanged()方法。其实这种设计也违反了“多用组合，少用继承”这个设计原则。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>观察者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式（一）——策略模式]]></title>
    <url>%2F2018%2F11%2F19%2FstrategyDesignPattern%2F</url>
    <content type="text"><![CDATA[系列关于设计模式，我之前也读过相关书籍（主要是这本《大话设计模式》）。当时边看这本书，边根据书中的一些例子写了一些博客（我的CSDN博客）。这些博客，一者现在看来大多都是流水账；二者因为在实际中运用到的设计模式真的不多（工作经历缺乏），因此也容易遗忘；三者，当初参照的书关于设计模式讲的真的不算太好，对于23种设计模式没有很明确的分类（比如重要性等），举的例子也说不上贴近现实和通俗易懂。那么前段时间（大概是618的时候），我买了一本《Head First设计模式》并且读完。这本书就我来看，水平以及对我的帮助是要高于上一本书的。并且在工作中，也确实感觉到了有熟悉设计模式的必要，因此看完后，我也生出了重新写一遍设计模式的念头。以下，便是要介绍的第一个设计模式——策略模式 Ⅰ. 什么是策略模式 策略模式就是定义一系列的算法，并将它们分别封装起来，使他们可以相互替换。策略模式使得算法以独立于客户而变化。策略模式涉及到以下几个角色： 1. 抽象策略角色：定义了具体策略需要实现的抽象方法或接口 2. 具体策略角色：封装具体的算法 3. 客户角色：内部持有策略类对象的引用 不明白没关系，来个例子就都清晰了～ Ⅱ. 举个例子以书中的“模拟鸭子游戏”为案例来具体讲述下这个模式～ 背景的这样的： 尼古拉斯·赵四是balabala公司的一名程序员。最近PM让他做一款“鸭子游戏”（很正经的游戏，游戏者可以选择不同的鸭子控制它叫或者让它游泳之类的，不过大概可能只有小朋友会玩吧 XD）。需求第一期要求做一个让鸭子叫的功能，赵四按照正常的设计逻辑，首先设计了一个鸭子Duck的超类（嗯～赵四是一个有基础OO素养的coder），在Duck类中他写了一个非抽象的quack方法（因为鸭子都会叫，那么这部分交给父类去完成）；然后还有一个抽象的display方法（毕竟不同种类的鸭子长得不一样嘛！），就像下面这样： 确定了设计方案以后，他设计了很多个类并且继承了Duck超类：普通鸭子，橡皮鸭子，绿头鸭，鸳鸯……他一口气写了这么多的类，但是好歹是完成了PM的需求，正想休息会。PM说“赵四呀，我们现在要给鸭子加上飞行的feature”。赵四：“加需求是不可能加的，这辈子都不可能加。我要是加，我赵四就从这跳下去！”PM：“我替hr和你说一声，明天去财务室报道”赵四：“我马上加班做！”赵四想，也挺简单嘛，在Duck类中加一个非抽象的fly方法就好了嘛！鸭子们都给我飞起来！ 5min后，测试妹子一脸便秘的来找赵四，“赵四，你脑子坏了么？？橡皮鸭子满屏幕地飞！”赵四：“我….”测试：“你什么你！赶紧改！”赵四看了下自己的设计逻辑，一下就找到了问题——并不是所有的鸭子都会飞，如果把飞行的行为加到父类中去实现，那就导致某些不适合该行为的子类也具有了飞行的功能。那应该怎么样做呢？赵四想到设计模式大师给他介绍过的一个设计模式——策略模式，感觉用在这个地方很合适啊！于是他将“鸭子游戏”系统通过策略模式进行修改： 首先构建鸭子的“飞行”行为接口 123public interface FlyBehavior &#123; void fly();&#125; 那么，我们可以通过实现FlyBehavior接口来创建不同的飞行行为 然后构建鸭子的“呱呱叫”行为接口 123public interface QuackBehavior &#123; void quack();&#125; 建立一个鸭子的抽象类 12345678910111213141516171819202122public abstract class Duck &#123; protected FlyBehavior flyBehavior; protected QuackBehavior quackBehavior; public abstract void display(); public void performFly() &#123; flyBehavior.fly(); &#125; public void performQuack() &#123; quackBehavior.quack(); &#125; public void setFlyBehavior(FlyBehavior flyBehavior) &#123; this.flyBehavior = flyBehavior; &#125; public void setQuackBehavior(QuackBehavior quackBehavior) &#123; this.quackBehavior = quackBehavior; &#125;&#125; 这是“鸭子”的抽象类，这里有一个“小心机”，在Duck类中持有着对FlyBehavior以及QuackBehavior接口的引用，并且有setter方法，那么我们就可以在使用的过程中“动态”地设定鸭子🦆的行为了！ 接下来是什么？来实现FlyBehavior吧 1234567public class FlyWithWings implements FlyBehavior&#123; @Override public void fly() &#123; System.out.println("I can fly! Flying with wings!"); &#125;&#125; 上面是一个“会飞”（而且是用翅膀飞）的飞行行为实现，再来一个“不会飞”的飞行行为（橡皮鸭子就不会飞对吧）！ 1234567public class CanNotFly implements FlyBehavior &#123; @Override public void fly() &#123; System.out.println("Fuck! I can't fly!"); &#125;&#125; 继续建立两个QuackBehavior的实现 1234567public class Quack implements QuackBehavior &#123; @Override public void quack() &#123; System.out.println("Quack! Quack! Quack!"); &#125;&#125; 上面这是是正常鸭子的叫声（”Quack! Quack! Quack!”），接下来建立一个“咩咩咩”叫的鸭子叫行为（高贵的赵四表示他也不知道为什么会有鸭子是咩咩叫的 - -） 1234567public class MewQuack implements QuackBehavior &#123; @Override public void quack() &#123; System.out.println("Mew! Mew! Mew!"); &#125;&#125; 接下来来建立两只不同的鸭子来做模拟！ 123456789public class RubberDuck extends Duck &#123; @Override public void display() &#123; System.out.println("Hi! It's a RubberDuck!"); performFly(); performQuack(); &#125;&#125; 第一只鸭子是一只橡皮鸭子，赵四觉得还需要一只“正常”的鸭子： 123456789public class NormalDuck extends Duck &#123; @Override public void display() &#123; System.out.println("Hi! It's a NormalDuck!"); performFly(); performQuack(); &#125;&#125; 最后，最后来建立一个鸭子游戏模拟器，来模拟下！ 123456789101112131415161718192021222324public class DuckGameSimulator &#123; public static void main(String[] args) &#123; FlyBehavior flyWithWings = new FlyWithWings(); FlyBehavior cantNotFly = new CanNotFly(); QuackBehavior quack = new Quack(); QuackBehavior mew = new MewQuack(); System.out.println("************* Duck 1 *************" + "\n"); Duck rubberDuck = new RubberDuck(); rubberDuck.setFlyBehavior(cantNotFly); rubberDuck.setQuackBehavior(mew); rubberDuck.display(); System.out.println("\n" + "************* Duck 2 *************" + "\n"); Duck normalDuck = new NormalDuck(); normalDuck.setFlyBehavior(flyWithWings); normalDuck.setQuackBehavior(quack); normalDuck.display(); &#125;&#125; 看下输出的结果！ 1234567891011************* Duck 1 *************Hi! It's a RubberDuck!Fuck! I can't fly!Mew! Mew! Mew!************* Duck 2 *************Hi! It's a NormalDuck!I can fly! Flying with wings!Quack! Quack! Quack! Ⅳ. 总结设计原则：将应用中变化的部分与固定的部分分离，并把“变化”进行封装，从而不影响应用其他的部分。这样就让系统的耦合降低，系统将更有弹性。]]></content>
      <tags>
        <tag>设计模式</tag>
        <tag>策略</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda+Stream对集合进行操作]]></title>
    <url>%2F2018%2F11%2F11%2FLambdaAndStreamOperate%2F</url>
    <content type="text"><![CDATA[写在前面Lambda表达式以及stream API是Java8才支持的两个功能。Lambda允许把函数作为一个方法的参数（函数作为参数传递进方法中），Lambda 表达式填补了Java对于函数式编程的空白；Stream API（java.util.stream）则把真正的函数式编程风格引入到Java中。两者结合可以带来很多奇妙的code体验！对很多初学者（比如我）来说，Lambda+Stream的方式一方面确实简化了代码的书写，让代码结构变得比较优雅，但从另一方面来说这样的代码风格，着实不容易看懂。但是随着实际的学习使用，我愈发感觉到这两者结合为开发带来了n多效率与快感！接下来就来探索下这种奇妙的编程style吧！ P.S. 此文不讲述最基本的lambda以及stream的概念和用法，只粗略的介绍下这种code方式在实际项目开发中的应用 假如有一个姓名的list和一个数字的list：： 12private static List&lt;String&gt; nameList = Arrays.asList("Pony", "Jack", "Gay", "Porsche", "Aston", "Maybach”);private static List&lt;Integer&gt; numberList = Arrays.asList(1, 2, 3, 4, 5, 6); ###1. 集合遍历如果要遍历nameList，传统的使用是通过for循环来实现的，如果利用lambda表达式，可以让遍历的代码变得更简洁明了： 12345678910111213// 常规方式遍历System.out.println("************ 以下为常规方式遍历list ************");for (String name : nameList) &#123; System.out.println("name:" + name);&#125;System.out.println("************ 以下为Lambda+函数操作 遍历list ************");// Lambda 函数操作nameList.forEach(name -&gt; System.out.println("name:" + name));System.out.println("************ 以下为Lambda+双冒号操作符 遍历list ************");// Lambda 双冒号操作符nameList.forEach(System.out::println); 输出结果如下：123456789101112131415161718192021************ 以下为常规方式遍历list ************name:Ponyname:Jackname:Gayname:Porschename:Astonname:Maybach************ 以下为Lambda+函数操作 遍历list ************name:Ponyname:Jackname:Gayname:Porschename:Astonname:Maybach************ 以下为Lambda+双冒号操作符 遍历list ************PonyJackGayPorscheAstonMaybach 可以看到运用了lambda表达式的遍历代码变的短小精悍。另外，我们先是用常用的箭头语法（-&gt;）创建 Lambda 表达式，然后还用了 Java 8 全新的双冒号操作符（::）。但是从输出结果上来看，双冒号操作符尽管简单，但却缺乏灵活及弹性。 ###2. filter()过滤 我们使用stream中的filter过滤器来过滤得到以”P”为开头的姓名： 12System.out.println("************ 以下为Lambda+Stream 过滤list ************");nameList.stream().filter(name -&gt; name.startsWith("P")).forEach(name -&gt; System.out.println("start with P: " + name)); 输出结果如下：123************ 以下为Lambda+Stream 过滤list ************start with P: Ponystart with P: Porsche 值得注意的是，stream的filter功能是“正向”的过滤，也就是说，是将符合filter内条件的数据“过滤”出来，而不是“排除”这些数据。 ###3. collect()方法 我们可以使用 collect 方法来将我们的结果集放到一个list，字符串， Set中: 123System.out.println("************ 以下为Lambda+Stream 过滤list 并输出为新的list ************");List&lt;String&gt; filterNameList = nameList.stream().filter(name -&gt; name.startsWith("P")).collect(Collectors.toList());filterNameList.forEach(name -&gt; System.out.println("filterName:" + name)); 输出结果如下：123************ 以下为Lambda+Stream 过滤list 并输出为新的list ************filterName:PonyfilterName:Porsche ###4. limit()限制结果集数目 我们不想要全部的结果集，只需要前面几行怎么办？easy，limit来帮忙！使用limit可以灵活限制结果集数目： 12System.out.println("************ 以下为Lambda+Stream 过滤list 并用limit 限制结果集数目 ************");nameList.stream().filter(name -&gt; name.startsWith("P")).limit(1).forEach(name -&gt; System.out.println("start with P: " + name)); 输出结果如下：12************ 以下为Lambda+Stream 过滤list 并用limit 限制结果集数目 ************start with P: Pony ###5. sorted()排序 可以看到，现在的nameList是无序的，使用sorted就可以进行简洁又灵活的排序了！我们来对nameList按照姓名的字典序进行排序吧： 12System.out.println("************ 以下为Lambda+Stream 通过名字的字典序对list排序 ************");nameList.stream().sorted((name1, name2) -&gt; (name1.compareTo(name2))).forEach(name -&gt; System.out.println("sorted name: " + name)); 输出结果如下：1234567************ 以下为Lambda+Stream 通过名字的字典序对list排序 ************sorted name: Astonsorted name: Gaysorted name: Jacksorted name: Maybachsorted name: Ponysorted name: Porsche ###6. min()和max()得到最小值及最大值 如果要获取排序后的最小值（序号最小）或最大值（序号最大）呢？使用min和max吧！ 1234System.out.println("************ 以下为Lambda+Stream 通过名字的字典序对list排序 后分别取出第一个及最后一个name ************");String minName = nameList.stream().min((name1, name2) -&gt; (name1.compareTo(name2))).get();String maxName = nameList.stream().max((name1, name2) -&gt; (name1.compareTo(name2))).get();System.out.println("minName: " + minName + ", maxName: " + maxName); 输出结果如下：12************ 以下为Lambda+Stream 通过名字的字典序对list排序 后分别取出第一个及最后一个name ************minName: Aston, maxName: Porsche ###7. map()来完成对stream中值的转换 对于numberList，我们要如何对其中每一个数进行平方运算呢？我们将 Lambda 表达式 x -&gt; x * x 传给 map() 方法，来对numberList中每一个元素进行操作。然后再打印看看吧： 123456// map将流中的一个值转换成一个新的值System.out.println("************ 以下为Lambda+Stream 使用map对numberList中对元素进行平方运算 ************");numberList.stream().map(x -&gt; x * x).forEach(System.out::println);```Java输出结果如下： ** 以下为Lambda+Stream 使用map对numberList中对元素进行平方运算 **149162536123456789###8. reduce()生成新的值对numberList中所有元素进行平方运算后，如果我们需要得到它们的和呢？我们使用 reduce() 将所有元素求和生成一个新的值：```JavaSystem.out.println(&quot;************ 以下为Lambda+Stream 使用map对numberList中对元素进行平方运算后 并用reduce生成新的值 ************&quot;);Integer newSum = numberList.stream().map(x -&gt; x * x).reduce((x, y) -&gt; x + y).get();System.out.println(&quot;newSum: &quot; + newSum); 输出结果如下：12************ 以下为Lambda+Stream 使用map对numberList中对元素进行平方运算后 并用reduce生成新的值 ************newSum: 91 以上只是介绍了Lambda+Stream对集合操作的一些简单的入门实践，希望能对你有帮助，也希望我们能在合适的地方灵活得运用它们～ 就是这样！希望你喜欢～]]></content>
      <tags>
        <tag>Lambda</tag>
        <tag>Stream</tag>
        <tag>集合</tag>
        <tag>Java8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java从Resource中读取.csv文件并进行处理]]></title>
    <url>%2F2018%2F10%2F24%2FreadResourceCSVFile%2F</url>
    <content type="text"><![CDATA[功能正常的java的maven工程中都有一个resources文件夹，里面存放着一些资源文件、spring容器启动时的xml文件等。当将一个.csv文件放到resources文件夹中，我们在代码中应该怎么读取和处理呢？ 主要步骤如下：1. 根据Resource文件所在的实际Path，用ClassLoader来获取文件的输入流inputStream2. 用字符缓冲输入流BufferedReader读取输入流inputStream3. 对文件按行顺序读取并处理 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class InformationReadTest &#123; private static final String pathName = "information_list.csv"; private static List&lt;String&gt; readResourceFile() &#123; InputStream inputStream = null; List&lt;String&gt; fileList = new ArrayList&lt;&gt;(); try &#123; // 根据Resource文件所在的实际Path，用ClassLoader来获取文件的输入流 inputStream = InformationReadTest.class.getClassLoader().getResourceAsStream(pathName); // 用字符缓冲输入流BufferedReader读取inputStream BufferedReader reader = new BufferedReader(new InputStreamReader(inputStream)); String line = null; // 对文件按行顺序读取 while ((line = reader.readLine()) != null) &#123; fileList.add(line); &#125; &#125; catch (Exception e) &#123; System.out.println("fail! " + e); &#125; return fileList; &#125; private static String getInformation(String information) &#123; if (StringUtils.isEmpty(information)) &#123; System.out.println("input information is null!"); return null; &#125; String[] strings = information.split(","); if (strings.length != 7) &#123; System.out.println("input information format is illegal!"); return null; &#125; String result = "姓名：" + strings[0] + ", 年龄：" + strings[1] + ", 职业：" + strings[2] + ", 地址：" + strings[3] + ", 爱好：" + strings[4] + ", 取向：" + strings[5] + ", 婚恋：" + strings[6]; return result; &#125; public static void main(String[] args) &#123; List&lt;String&gt; fileList = readResourceFile(); // 用了一个lamda表达式来循环处理fileList fileList.stream().forEach(fileString -&gt; &#123; String result = getInformation(fileString); System.out.println(result); &#125;); &#125;&#125; 运行结果如下： 123姓名：王小明, 年龄：17, 职业：学生, 地址：浙江省杭州市, 爱好：健身, 取向：直男, 婚恋：没有女朋友Process finished with exit code 0 工程结构如下： P.S. main方法中用了一个Lambda表达式，这个我们在接下来对博客中会讲一讲Lambda表达式对一些用法～ 喜欢你喜欢～]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Resource</tag>
        <tag>csv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过HttpServletResponse实现浏览器文件下载及坑点介绍]]></title>
    <url>%2F2018%2F10%2F20%2FhttpServletResponseDownloadFile%2F</url>
    <content type="text"><![CDATA[功能最近在做一个需求————通过一个Controller将相关数据转成csv文件后直接让浏览器下载。思路呢，比较清晰，主要的流程如下：1. 设置响应的ContentType类型2. 设置响应头3. 通过httpServletResponse获取ServletOutputStream对象4. 将需要的数据写到输出流中 这里给出示例代码如下： 12345678910111213141516171819202122232425262728293031323334/** * 下载数据 */ @RequestMapping("/downloadCSVFile") public void downloadCSVFile(HttpServletResponse httpServletResponse) &#123; try &#123; // 设置ContentType httpServletResponse.setContentType("application/x-download;charset=utf-8"); // 设置文件名，并指定编码格式 String fileName = URLEncoder.encode("download_records_" + System.currentTimeMillis() / 1000 +".csv", "UTF-8"); httpServletResponse.setCharacterEncoding("UTF-8"); // 将文件名addHeader httpServletResponse.setHeader("content-disposition", "attachment;filename=" + fileName); String message = "test"; InputStream stream = new ByteArrayInputStream(message.getBytes("UTF-8")); OutputStream out = httpServletResponse.getOutputStream(); byte buff[] = new byte[1024]; int len = 0; while ((len = stream.read(buff)) &gt; 0) &#123; out.write(buff, 0, len); &#125; out.flush(); out.close(); stream.close(); &#125; catch (Exception e) &#123; logger.error("download output error!", e); &#125; &#125; 代码很简单，首先我们设置了httpServletResponse的ContentType为application/x-download，用于表面我们要传输应用程序数据或者二进制数据。随后设置response的头为content-disposition。content-disposition用来对报文体进行描述，规定了客户端的显示处理行为；有两种取值：attachment和inline，分别表示保存和直接显示。并且我们设置了文件名及保存的格式然后将我们需要的数据通过写入httpServletResponse中完成我们需要的功能。 当我们部署好以后，访问controller的域名即可完成下载。 好了，我知道这么尝试的同学都能顺利成功的。 那么我想说的问题是什么？问题是当通过前端的页面进行下载时不会出现文件下载，只会在前端的response中显示我传输的内容；而直接通过网页访问页面是可以正常下载的！ 问题的原因与解决方案原因一开始找原因是极其难的，因为我们根本不知道前端哪里出了问题。后来在一篇文章中（Javascript/jquery通过POST用JSON数据下载文件）推测了原因：前端在请求时借用了ajax来进行。但是ajax是不直接支持下载文件的，换而言之，不能直接通过向httpServletResponse写文件流并通过ajax下载！ajax支持的dataType只有如下几种:：xml、html、script、json、jsonp和text。有了如下推测，直接联系前端同学，问她（对的，是个妹子呢，前端就是妹子多）是不是用了ajax，一贴代码，果然如此～ 解决方案让前端不要通过ajax请求就好了～so easy～ ok！done！]]></content>
      <tags>
        <tag>HttpServletResponse</tag>
        <tag>文件</tag>
        <tag>下载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过Apache的Http框架以"application/x-www-form-urlencoded"形式post数据的两种方式]]></title>
    <url>%2F2018%2F10%2F13%2FhttpPostDataTranser%2F</url>
    <content type="text"><![CDATA[简介最近与第三方公司作业务对接时，需要我方将数据通过http请求的方式传输到对方接口，我方一直通过将对应的数据对象以“json”的格式放在http请求体中。联调后对方表示一直读不到数据。经过很多方式的探索后发现，对面是用“key-value”的方式在读取数据，怪不得拿不到数据！因为我们的http请求都是通过Apache的Http框架来建立的，接下里我就简单介绍下通过Apache的Http框架，以”application/x-www-form-urlencoded”形式post数据的两种方式。 这里给出示例代码如下： 两种方案1. 数据以”json”格式传输代码如下： 123456// 建立HttpPost对象HttpPost postReq = new HttpPost(url);// 设置通过contentType和请求数据来建立请求体StringEntity entity = new StringEntity(data, ContentType.create("application/x-www-form-urlencoded", characterSet));postReq.setEntity(entity);// 以下为http请求的其他配置设置等 2. 数据以”key-value”形式传输键值对的存放需要通过BasicNameValuePair对象来实现 代码如下： 1234567891011121314// 建立HttpPost对象HttpPost postReq = new HttpPost(url);// 建立一个map来存放"key-value"对Map&lt;String,String&gt; parameters =JSON.parseObject(data, Map.class);// 新建NameValuePair列表，用来存放键值对List&lt;NameValuePair&gt; NameValuePairList = new ArrayList&lt;NameValuePair&gt;();for (String key : parameters.keySet()) &#123; NameValuePairList(new BasicNameValuePair(key, parameters.get(key)));&#125;// 通过UrlEncodedFormEntity将NameValuePairList进行格式化后放入请求体中postReq.setEntity(new UrlEncodedFormEntity(NameValuePairList, characterSet));// 设置contentTypepostReq.setHeader("Content-Type", "application/x-www-form-urlencoded");// 以下为http请求的其他配置设置等 ok！done！]]></content>
      <tags>
        <tag>Apache</tag>
        <tag>Http</tag>
        <tag>post</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Arraylist add方法的java.lang.UnsupportedOperationException异常]]></title>
    <url>%2F2018%2F10%2F01%2FArraysException%2F</url>
    <content type="text"><![CDATA[问题最近在对list进行code的时候抛出了java.lang.UnsupportedOperationException异常，且看代码： 12345678910111213141516171819202122232425262728293031public class BlogCaseTest &#123; private static Map&lt;String, List&lt;String&gt;&gt; cityMap = new HashMap&lt;&gt;(); public static void main(String[] args) &#123; String[] provinceString = &#123;"zhejiang", "zhejiang", "shanghai", "sichuan"&#125;; String[] cityString = &#123;"hangzhou", "jiaxing", "shanghai", "chengdu"&#125;; for (int i = 0; i &lt; provinceString.length; i++) &#123; cityMapInitialize(provinceString[i], cityString[i]); &#125; &#125; private static void cityMapInitialize(String province, String city) &#123; if (StringUtils.isEmpty(province) || StringUtils.isEmpty(city)) &#123; System.out.println("illegal input province or city"); return; &#125; try &#123; if (!CollectionUtils.isEmpty(cityMap.get(province))) &#123; List&lt;String&gt; cityList = cityMap.get(province); cityList.add(city); &#125; else &#123; List&lt;String&gt; cityList = Arrays.asList(city); cityMap.put(province, cityList); &#125; System.out.println("province: " + province + " city: " + city); &#125; catch (Exception e) &#123; System.out.println("province: " + province + " city: " + city + " cityMapInitialize exception! " + e); &#125; &#125;&#125; 代码很简单，首先定义一个cityMap用来存储“省份-城市”的映射，cityMapInitialize方法用来对cityMap进行初始化或者说赋值，执行main函数后，控制台输出如下： 1234province: zhejiang city: hangzhouprovince: zhejiang city: jiaxing cityMapInitialize exception! java.lang.UnsupportedOperationExceptionprovince: shanghai city: shanghaiprovince: sichuan city: chengdu 可以看到当执行到“zhejiang-jiaxing”的时候，抛出了异常 原因与解决方案原因原因很简单，请看第19-25行代码：1234567if (!CollectionUtils.isEmpty(cityMap.get(province))) &#123; List&lt;String&gt; cityList = cityMap.get(province); cityList.add(city); &#125; else &#123; List&lt;String&gt; cityList = Arrays.asList(city); cityMap.put(province, cityList); &#125; 当cityMap中没有对应的province时，我们先通过Arrays.asList来新建一个list并put到cityMap中，而当cityMap中已经存在此province的映射时，就会取出province对应的list，并将此时的city加入到list中。那么，问题就来了————通过Arrays.asList创建的list是固定大小的ArrayList。请看Arrays中asList的源码： 12345678910111213141516171819202122/** * Returns a fixed-size list backed by the specified array. (Changes to * the returned list "write through" to the array.) This method acts * as bridge between array-based and collection-based APIs, in * combination with &#123;@link Collection#toArray&#125;. The returned list is * serializable and implements &#123;@link RandomAccess&#125;. * * &lt;p&gt;This method also provides a convenient way to create a fixed-size * list initialized to contain several elements: * &lt;pre&gt; * List&amp;lt;String&amp;gt; stooges = Arrays.asList("Larry", "Moe", "Curly"); * &lt;/pre&gt; * * @param &lt;T&gt; the class of the objects in the array * @param a the array by which the list will be backed * @return a list view of the specified array */ @SafeVarargs @SuppressWarnings("varargs") public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a); &#125; 解决方案很简单，创建初始的list时，不要创建如上所述的固定大小的ArrayList。如下： 12345678if (!CollectionUtils.isEmpty(cityMap.get(province))) &#123; List&lt;String&gt; cityList = cityMap.get(province); cityList.add(city); &#125; else &#123; List&lt;String&gt; cityList = new ArrayList&lt;&gt;(); cityList.add(city); cityMap.put(province, cityList); &#125; ok！done！]]></content>
      <tags>
        <tag>Java</tag>
        <tag>异常</tag>
        <tag>List</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BASE64编码结果存在“换行符”及解决方案]]></title>
    <url>%2F2018%2F09%2F18%2FBASE64encode%2F</url>
    <content type="text"><![CDATA[问题今天与第三方服务器进行http请求交互时，发现传入的signature与服务器signature对不上导致请求失败。后发现是在调用sun.misc包下的BASE64Encoder().encode()方法对字符串“content”进行编码时，编码结果与服务器的标准值对不上。调试后发现本地编码结果中莫名其妙混入了很多“换行符”（\t）： 12345671iIiwiU2VuZGVyQWRkcmVzcyI6Iua1i+ivleWcsOWdgCIsIlNlbmRlck5hbWUiOiLlvKDkuIkiLCJSZWNlaXZlclByb3ZpbmNlIjoi5rGf6IuPIiwiU291cmNlSWQiOiIxMjM0NTYiLCJTZW5kZXJEaXN0cmljdCI6Iuemj+eUsOWMuiIsIlJlY2VpdmVyTW9iaWxlIjoiMTUyOTk5OTk5OTkiLCJTZW5kZXJQcm92aW5jZSI6IuW5v+S4nCIsIlJlY2VpdmVyRGlzdHJpY3QiOiLlp5Hoi4/ljLoiLCJSZWNlaXZlckNpdHkiOiLoi4/lt57luIIiLCJSZWNlaXZlck5hbWUiOiLlvKDkuIkiLCJTZW5kZXJNb2JpbGUiOiIxNTE4ODg4ODg4OCIsIlNlbmRlckNpdHkiOiLmt7HlnLPluIIifQ== 原因与解决方案原因查询了发现在RFC2045中有这么一段规定： 1REQUIRES that encoded lines be no more than 76 characters long. If longer lines are to be encoded with the Quoted-Printable encoding, &quot;soft&quot; line breaks 意思就是：BASE64一行不能超过76字符，超过就会添加回车换行符。原因就是这样，下面给出解决方案。 解决方案可以通过在BASE64编码的结果后加上 .replaceAll(“\r|\n”, “”) 解决 ok！done！]]></content>
      <tags>
        <tag>BASE64</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring中加载配置文件的两种方式]]></title>
    <url>%2F2018%2F09%2F08%2FspringLoadProperties%2F</url>
    <content type="text"><![CDATA[前言在实际项目开发中经常会根据不同的环境（dev,pre,online）来配置不同的类或属性，比如说根据不同的环境配置不同的zookeeper或者数据库datasource。最简单的无非就是开发人员根据不同的环境人肉去修改对应的配置，这种方式简单但却费时，且很容易出错：极其容易出现配置写错或者忘记修改对应环境配置的情况。对于要解放双手的程序员来说，这无疑是一种很low又很低效的方式。这个时候就可以用spring读取不同的环境配置文件（比如说zookeeper.properties），然后用maven的多环境打包的方法就可将对应环境的属性注入。配置文件的存在解决了很大一份重复的工作，并且也方便了我们统一管理配置。 I. 介绍两种读取配置文件的方法那么首先要解决的通过spring来读取配置文件。一般有以下几种方式可以来读取配置文件：1. 通过xml注入2. 通过@Value注解注入 1. 通过xml注入首先，我们新建一个User类： 1234567@Data@ToStringpublic class User &#123; private String name; private String city; private String phone;&#125; @Data和@ToString是lombok的注解，是为了省去写getter，setter及toString方法的神器，当然还有很多人认为lombok的注解是邪教- -，好吧，这不是咱们今天要说的重点 可以看到User类中存在三个私有变量，我们的目的就是通过资源文件中的配置来注入到这三个变量中 那么，我们来建立一个资源文件——user.properties，内容如下： 1234#useruser.name = $&#123;test.user.name&#125;user.city = $&#123;test.user.city&#125;user.phone = $&#123;test.user.phone&#125; 其中，${test.user.name}、${test.user.city}、${test.user.phone}分别对应环境资源文件中的属性。因为实际项目开发中需要根据不同的环境打包不同的环境资源文件，因此不同的环境都会对应一份环境资源文件，例如dev_config.properties对应线下开发环境，pre_config.properties对应预发环境，online_config.properties对应线上正式环境。以下我们给出线下环境的资源文件（dev_config.properties）配置： 1234#usertest.user.name = Olivetest.user.city = hangzhoutest.user.phone = 16668815388 为了让spring可以注入properties文件中的配置，首先需要在xml中配置扫描包下的java文件： 1&lt;context:component-scan base-package="com.xxx.xxx.service"/&gt; 然后需要在spring的xml配置文件中添加以下两个类的实例，这两个类用来加载prperties文件，这两个类真的很重要！已经遇到无数起因为没有配置这俩类导致的大坑： 12org.springframework.beans.factory.config.PropertiesFactoryBeanorg.springframework.beans.factory.config.PreferencesPlaceholderConfigurer 配置如下： 1234567891011&lt;bean id="configProperties" class="org.springframework.beans.factory.config.PropertiesFactoryBean"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;value&gt;classpath*:message.properties&lt;/value&gt; &lt;value&gt;classpath*:user.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PreferencesPlaceholderConfigurer"&gt; &lt;property name="properties" ref="configProperties" /&gt;&lt;/bean&gt; list标签的value写明了要扫描的properties文件的名字，当然也可以暴力地扫描所有properties文件： 1&lt;value&gt;classpath*:*.properties&lt;/value&gt; 接下来我们就可以注册User的bean，然后将对应属性注入到类的私有域中： 12345&lt;bean id="user" class="com.mogujie.trade.third.service.sync.User"&gt; &lt;property name="name" value="$&#123;user.name&#125;"/&gt; &lt;property name="city" value="$&#123;user.city&#125;"/&gt; &lt;property name="phone" value="$&#123;user.phone&#125;"/&gt;&lt;/bean&gt; 然后我们写个单测跑一跑： 1234567891011@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;"classpath*:spring-biz.xml"&#125;)public class UserTest &#123; @Autowired private User user; @Test public void testUserProperties() &#123; System.out.println("System out: " + user.toString()); &#125;&#125; 看下结果： 1System out: User(name=Olive, city=hangzhou, phone=16668815388) ok！done！ 2. @Value注解要使用@Value注解，那么我们首先要对User类做出修改，因为之前是通过xml注册user bean，现在则需要显式地用@Service修饰User类，并且给User类的私有域都加上@Value注解（此时就不用通过xml来注册user bean）： 1234567891011@Service("user")@Data@ToStringpublic class User &#123; @Value("$&#123;user.name&#125;") private String name; @Value("#&#123;configProperties['user.city']&#125;") private String city; @Value("$&#123;user.phone&#125;") private Long phone;&#125; 重新跑下单测，成功了～结果和上面一样的，就不贴出来了 另外， 我们可以看到在city上的@Value注解用的是”#{}”，了解@Value注解的同学可能知道有两种设置属性值的方法：@Value(“#{}”)与@Value(“${}”)。那么这两种方式有什么区别呢？ 2.1 @Value(“#{}”) SpEL表达式@Value(“#{}”) 表示SpEl表达式通常用来获取bean的属性，或者调用bean的某个方法。当然还有可以表示常量。@Value(“#{configProperties[‘user.city’]}”)注解中有configProperties，指的是配置文件的加载对象，即我们最开始强调的要在xml中注册的configProperties bean 2.2 @Value(“${t1.msgname}”)这种形式不需要指定具体加载对象，这时候需要实例化PreferencesPlaceholderConfigurer类对象。此对象配置可以可以直接复用configProperties对象中的配置，也可以自定配置文件路径。可以看到，我们在一开始就注册了这个bean。 有兴趣的同学可以验证一下上面两个配置文件（我当然验证过了咯:D） done！ II. 相关博客推荐[1]. Spring注入值（Value注解）[2]. spring(基础10) 注解@Value详解]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
        <tag>配置文件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引及查询优化（三）——索引设计概述]]></title>
    <url>%2F2018%2F09%2F04%2FsqlIndexAndQueryOptimize-3%2F</url>
    <content type="text"><![CDATA[写在前面终于写到这个系列最后一篇文章了，前两篇第一篇通过慢查询日志分析了sql语句，第二篇讲述了索引等概念、类型，并且讲述了如何通过explain指令来对sql进行分析，最后也给出了一些查询实例。今天第三篇，主要会讲下mysql中索引的普适性设计方案（比如三星索引等概念及设计思路）以及评判索引性能的两种方法。 Ⅰ. 基本概念与假设1. 对db表的读取： 从磁盘中进行一次随机I/O，即将一个页从磁盘中读取至数据库缓冲池：大约10ms 从磁盘服务器的缓存中进行读取，当dbms需要的页不在数据库缓冲池中，会向磁盘服务器发起请求，服务器首先回去查询此页是否在缓冲区中，若在缓冲区中，读取的时间将大幅降低：1ms 对磁盘进行顺序读取，上面说的都是将一个表页读取到缓冲池的情况，很多时候我们会需要读取多个页到缓冲池中，然后进行顺序处理，同时读取多个页将减少每个页被平均读取的时间：0.1ms 2. 访问dbms读取一个索引行或一个表行称为一次访问：索引访问或表访问。若dbms扫描索引或表的一个片段（被读取的行在物理上相邻），那么第一次读取为随机访问（TR），后续行的读取为顺序访问（TS）。 3. 谓词where语句中的条件被称为 谓词 4. 索引片及匹配列索引片是sql查询在执行过程中扫描的一个索引片段，在这个范围中的索引将被顺序扫描；索引片的厚度指 谓词表达式确定的范围，索引片越窄说明匹配到的数据行数越少，那么索引访问及对表的读取的开销越小。另一种广泛描述索引片的方法是定义 索引匹配列的数量。 5. 索引匹配列和过滤列有些列可能同时存在于where子句中与索引中，但是这个列所在的索引却不能生效（比如之前所说的，where子句中碰到范围查询，其后的索引列将不生效），这样的列称为过滤列，因为通过索引上的过滤列能够避免回表访问。与过滤列相对的，如果where条件中的一列同时在索引中，并且能参与索引的定义，那么这列就是匹配列。 6. 过滤因子其描述了谓词的选择性，即满足where条件的记录占所有记录总数的比例。在评价索引是否合适时，过滤因子很重要。并且在实际中，一般考虑最差情况下的过滤因子，而不是平均过滤因子。 Ⅱ. 最优索引概念及设计思路1. 三星索引三星索引是一个概念，表示对于一个查询来说最理想的索引。既然是三星索引，那必然是有三颗星，那么星级如何确定呢？如果与一个查询相关的索引行是相邻的，或者至少足够靠近的话，那这个索引就可以被标记上第一颗星。这最小化了必须扫描的索引片的宽度； 如果索引行的顺序与查询语句的需求一致，则索引可以被标记上第二颗星。这排除了排序操作； 如果索引行包含查询语句中的所有列——那么索引就可以被标记上第三颗星。这避免了访问表的操作，仅访问索引就可以了。 对于这三颗星，第三颗通常是最重要的（其实这里的说明很理论也很拗口，下面会给出具体例子来说明）。 2. 宽索引与窄索引宽索引是指一个至少满足第三颗星的索引，此索引包含了select语句所涉及的所有列，因此该查询只需访问索引而不必回表查询。 3. 举个三星索引设计的栗子：比如说如下的一条sql： 1select sex from user where name=“jack” and city=“hangzhou” order by age 第一颗星：取出所有等值谓词的列（即where条件后的列：name和city），将name和city作为索引的开头，并且不要求严格的顺序。这可以使索引片宽度缩短至最窄 第二颗星：将用来排序的列（oder by age）加入到索引中。那现在索引就变成：name_city_age 第三颗星：将查询语句剩余的列加到索引中去，列在索引中的顺序对查询性能无影响。此时索引将变成name_city_age_sex，这个索引就是三星索引 4. 索引星级的选择能设计出三星索引，无疑是最好的情况（不考虑存储索引等的开销），但在很多实际情况下，是无法设计出理想的三星索引的。换句话说，对于索引的某些星级我们必须要进行舍弃。 举个例子： 1select sex from user where age between a and b and city=“hangzhou” order by name 在这个sql中，age是一个范围条件，在前面的博客中（mysql索引及查询优化（一）——从慢查询实例中开始分析）我们说过，如果索引列是一个范围条件，那么其后的索引都将失效。那这个时候索引该如何设计？在前面说过，索引的第三颗星通常是最重要的，那么我们先设计第三颗星，索引将是：*_user。添加name会让索引满足第二颗星，但这是基于name必须在范围谓词age的前面的假设的，那么此时索引将变成:name_age_sex或者city_name_age_sex，那么此时的索引满不满足第一颗星的，答案是不满足的。讲到这里，我们一定能发现，第一颗星和第二颗星是存在互斥的，如果要满足第一颗星，那么索引将是city_age_name_sex，然而此时name列索引是不会生效的，此时就无法避免排序，也即无法满足第二颗星。综上所述，在这种情况下，我们是无法设计出理想的三星索引的，我们必须要进行取舍。至于是选第一颗星还是第二颗星，一个普遍的结论（虽然并不是完全正确的）是第一颗星要比第二颗星重要，因为在硬件发展水平如此快速的今天，可能排序带来的开销远低于因为索引片太厚而带来的查询开销。 另外，虽然理论上为每一个查询都设计出最优的索引看似是比较好的，然而真正这么做的时候我们需要考虑下开销：首先过多的索引会占用大量的磁盘空间，我们需要评估索引带来的收益是否能抵消磁盘空间带来的开销；其次表上有太多的索引（并且这些索引可能存在冗余），会使db的插入、更新与删除操作变得较慢；最后，较频繁的插入频率，可能会加大磁盘的负载。所以，理论终究只是理论，具体问题还需要具体分析。 Ⅲ. 如何设计及评估索引性能首先给出两个快速且有用的方法：1. 基本问题法（Basic Question, BQ）2. 快速上限估算法（Quick Upper-Bound Estimate, QUBE） 1. 基本问题法BQ是一个很简单很快速的评估方法，对于每一个查询语句，首先都要问这么一个问题： 是否存在一个索引包含了where子句所用到的所有列？如果答案是不存在，那么应该考虑将缺少的列加入到现有的索引中去。此时会产生一个半宽索引，虽然这样索引只能拿到一星，但索引过滤可以保证回表访问只发生在所有查询条件都满足的时候。如果性能还不够，那么可以将查询所有涉及到的列都加到索引上，这会产生一个避免所有表访问的宽索引。如果查询还是很慢，那么就重新设计索引～ 2. 快速上限估算法。相比于BQ，QUBE是一个比较耗时的方法，但是它的优点也很明显——QUBE可以估算出查询的性能。QUBE通过计算本地响应时间（LRT）来评估查询的性能。我们只使用TR（随机访问的数量）和TS（顺序访问的数量）来进行查询耗时的估算。 QUBE中假设单次随机访问的时间为10ms，顺序随机访问的时间为0.1ms 3. QUBE示例： 3.1 主键索引访问：考虑如下的sql（假设id为主键）：select id, age, city from user where id = xxx通过主键索引读取一个表行需要分别随机访问一次表以及索引，因此此查询的开销大约是2x10ms=20ms。3.2 聚簇索引访问： 1select id, age from user where city = xx and post = xxx order by age 假如city_post_age是一个聚簇索引，并且杭州市内邮政编码为xxx的用户有1000个，可以通过三星索引法分析这个索引是两星的（第一颗及第二颗），但是是不满足的第三颗星的，它必须回表去访问不在索引列中的列。首先，需要进行一次随机访问找到索引片上第一条符合条件的索引行，这是一次TR，然后需要1000次TS来读取索引，因此读取索引片的开销为1x10ms+1000x0.01ms=20ms；然后来计算回表的开销，回表需要一次TR，以及999次TS，所以回表的开销大约也是20ms。因此这条sql总的耗时大约是40ms。3.3 非聚簇索引访问：还是如上的sql，如果city_post_age不是一个聚簇索引，那么我们知道，回表的访问将变成1000次的TR，此时回表的耗时将是10s！此时可以考虑将id加入到索引city_post_age中，这样便省去了回表查询的开销。 Ⅳ. 总结这次我们首先定义了一些假设及概念，然后提出了“三星索引”的概念及设计思路，最后讲述评估索引性能的两个方案。总的来说，我认为这里所提出的索引设计及评估的方案都是简单易用的，有兴趣的不妨试试看。BTW，其实我觉得explain也是一个很好的分析性能的方法，在索引建立完之后，不妨使用explain来分析下查询的性能～ Ⅴ. Reference[1]. Lahdenmaki T, Leach M. Relational Database Index Design and the Optimizers[M]. Wiley-Interscience, 2005.[2]. Schwartz B, Zaitsev P, Tkachenko V. High Performance MySQL: Optimization, Backups, and Replication[M]. O’Reilly Media, Inc. 2012.]]></content>
      <tags>
        <tag>sql</tag>
        <tag>数据库</tag>
        <tag>索引</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引及查询优化（二）——索引概述]]></title>
    <url>%2F2018%2F08%2F30%2FsqlIndexAndQueryOptimize-2%2F</url>
    <content type="text"><![CDATA[写在前面隔了那么久，终于写了索引及查询优化的第二篇博文，确实用了好长的时间去看书，看博客然后总结。然而，不得不说我之前对sql以及索引相关的知识了解确实甚少（并且在实际中用的也不太多），因此即使补充了一些相关知识， 写出来的文章也会有很多的不足与纰漏。在此也希望从文章中看出有什么不足的朋友可以尽情批评指正～这篇博客主要分三个部分，第一部分简单介绍了索引的概念及类型；第二部分介绍了如何通过Explain指令分析sql；第三部分给出了一些sql的实例。 Ⅰ. 索引概念及类型1 索引概念索引是存储引擎用来快速找到记录的一种数据结构。类似于书目录，如果我们想要找“第三章第四小节”的内容，那么我们首先先从目录中找到其所在的页数，然后再从具体的页中找到我们需要的数据。索引也是一样，在查询时，先找到索引所在的位置，然后根据索引匹配到的记录来找到对应的数据。 2 索引类型 2.1 b-tree索引b-tree索引是mysql引擎中用的较多的一种类型，大多数的引擎都支持，除了archive引擎（对这个好陌生 - -）。不同的存储引擎使用不同的b-tree索引，并且性能也有差别。比如在innodb引擎中使用b+tree索引。myisam引擎会对索引进行前缀压缩，所以索引很更小；myisam中索引通过数据的物理位置来引用索引行，而innodb中根据主键引用索引行。b-tree索引对索引按照顺序组织存储的，因此适合查找范围数据。 B-tree索引在实际开发中是用的最多最广泛的索引结构，之后的讨论都默认是以B-tree索引为例。在某些不当的查询或者索引的使用中会导致索引失效，主要有以下这几种情况： 严格遵循最左匹配原则。即查询必须从索引的最左前列开始。比如一个索引(name_age_dob)，如果要查询age=18的用户，就无法使用(name_age_dob)这个索引了。 不能跳过索引中间的列。比如我们要查找age=18并且dob=1024的用户，但不指定age，那么就无法使用到(name_age_dob)索引，只能使用索引的第一列。 查询中某个列出现了范围查询，那么它右边的列都无法通过索引来进行优化查询。这在前一篇博客（xxxx）中就讲述过。 索引字段上使用了（!= &lt;&gt; is null is not null or 或者like以”%_” 开头）等会导致索引失效而转入全表扫描 对索引列进行操作（这里指索引列不能是表达式的一部分，也不能是函数的参数），比如下边的sql就不能使用索引，明眼人一看就知道id=1023啊，然而Mysql引擎并不会那么的智能，所以我们在查询时能简化条件就简化条件，越简单越好。 1select id from user where id+1=1024 2.2 哈希索引哈希索引基于哈希表实现，mysql引擎中只有memory支持哈希索引，我们知道哈希表会存在“哈希碰撞”的问题，memory引擎根据链表法来解决键值冲突的情况。类比于哈希表，使用哈希索引查找的速度十分快。但也有一些限制： 哈希索引只包含哈希值以及行指针，不存储具体字段的值，所以不能根据匹配索引来避免读取表行 哈希索引的数据不是按照索引值顺序存储的，因此无法用于排序（这个应该很好理解） 哈希索引因为是根据对key进行hash来查找的，因此不支持部分索引匹配的情况。 哈希索引不支持范围查询，只支持等值查询（注意IN()也是一种等值查询！） 上面说到了哈希碰撞，如果碰撞过多，哈希索引的性能将受很大的影响 2.3 全文索引全文索引查找的是文本中的关键词，而不是直接比较索引中的值。用的不多（我根本没用过），这也不是我想说的重点，所以不详细展开。 2.4 聚簇索引首先，聚簇索引并不是一种简单的索引类型，而是一种数据存储方式。在innodb中，聚簇索引实际在一个结构中同时保存了b-tree索引以及数据行。 聚簇索引的数据的物理存放顺序与索引顺序是一致的，即：只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。因为一张表只有一个物理结构，因此一张表也只能有一个聚簇索引。聚簇索引的叶子节点就是数据节点，而非聚簇索引的叶子节点仍然是索引节点，并且有指向对应数据块的指针。innodb默认会以主键作为聚簇索引，如果没有定义主键，innodb会选择一个唯一的非空索引来代替。如果前面的情况都不满足，那么innodb会隐式定义一个主键来作为聚簇索引。 2.5 覆盖索引覆盖索引（Covering Index）也不是常规意义上的索引。如果一个索引包含了所有查询需要的字段，那么久称这个索引为“覆盖索引”。使用“覆盖索引”可以极大提高查询性能。 Ⅱ. SQL分析在进行sql分析时，explain语句是一个常用的方法，我们将举出一些sql的查询来进行分析，以下的例子都来自于Refund表（这张表与第一篇博文中使用的表相同，地址：mysql索引及查询优化（一）——从慢查询实例中开始分析） explain得到的结果分析: 请看下图的例子： 首先我们来解释下explain结果的各个列的含义： id:表示select子句执行的id，如果是子查询，id的序号就会递增了，并且id值越大的子句越先被执行 select_type:表示select语句的类型，比如：SIMPLE（简单查询，不包含子查询或者UNION）；PRIMARY 查询中若包含任何复杂的子部分，最外层查询则被标记为PRIMARY，具体不展开了，可以自行搜索 table:当前执行的表名 type：当前表内访问方式，访问方式从好到坏排序为： system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; allsystem指表只有一行记录；const表示查询了一次就找到结果；eq_ref表示唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配；ref表示非唯一索引扫描；range 表示只检索给定范围的行，使用一个索引来选择行；index表示查询扫描了索引树；all表示全表扫描 possible_keys:可能使用到的索引 key:经过优化器评估最终使用的索引 key_length:使用到的索引长度 ref:引用到的上一个表的列rows:要得到最终记录索要扫描经过的记录数，rows值越小说明查询越高效 Extra:额外的信息说明，主要的类型有：Using filesort：文件排序，说明mysql无法利用索引完成排序Using temporary：临时表， 使用了用临时表保存中间结果，MySQL在对查询结果排序时使用临时表，这个时候效率是极其低下的Using index：表示相应的select操作中使用了覆盖索引（Covering Index），避免访问了回表访问数据Using where：使用了where过滤Using join buffer：使用了连接缓存impossible where：where子句的值总是false，不能用来获取任何元组Using index condition：Using index condition 会先条件过滤索引，过滤完索引后找到所有符合索引条件的数据行，随后用 WHERE 子句中的其他条件去过滤这些数据行 Ⅲ. 实例分析请看如下的sql：1explain select* from Refund where sellerUserId=93106308 因为索引无法覆盖查询所需要的全部列，因此Extra中显示“Using index condition”： 再看这个SQL：1explain select status from Refund where status=700 order by created 这里进行了文件排序： 覆盖索引查询：1explain select sellerUserId, status, created from Refund Refund表中有一个多列索引：KEY idx_sellerUserId_created_status (sellerUserId,created,status)，如果只访问sellerUserId, status, created这三列，查询将使用“覆盖索引”：具体执行结果如上图所示，在type列中显示了“index”，这表示此次查询将通过索引来访问数据；Extra中的“Using index”表示此次查询将使用“索引覆盖”查询。 最后一个sql例子：1explain select status from Refund where sellerUserId=93106308 order by created 这句sql中的Extra不仅出现了“Using index”还出现了“Using where”，这表示索引被用来执行索引键值的查找；如果没有同时出现“Using where”，表明索引用来读取数据而非执行查找动作。 Ⅳ. Reference[1]. EXPLAIN用法和结果分析：https://blog.csdn.net/why15732625998/article/details/80388236[2]. Schwartz B, Zaitsev P, Tkachenko V. High Performance MySQL: Optimization, Backups, and Replication[M]. O’Reilly Media, Inc. 2012.]]></content>
      <tags>
        <tag>sql</tag>
        <tag>数据库</tag>
        <tag>索引</tag>
        <tag>优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正式告别CSDN]]></title>
    <url>%2F2018%2F08%2F08%2F20180808-sayByeToCSDN%2F</url>
    <content type="text"><![CDATA[终于有了自己的博客CSDN拜拜👋～无数次被csdn蠢哭！一是愚蠢的人工审核方式；二是捉急的app后台，老奔溃。老实说，之前12306是我见过的最傻最蠢的app！好了，csdn刷新我记录了。现在我把这个title颁给您！请您务必接受！BTW，现在终于也搭建了自己的博客～ blog4olive.top域名不算好听（穷困的我这辈子都买不起好听的域名！可以考虑给我众筹。刚好添加了打赏功能，文章末尾即可看到！），但胜在简单明了对吧？ 关于博客更新 增加了文章pv 博客pv的显示 页脚icon等的优化 文章结构显示 文章搜索功能 打赏 TODO: 评论功能 分享 代码高亮等格式优化 更美观更优雅 之后csdn的博客都要迁移过来，工程量巨大，想打人 那么继续加油吧! 送上一张美照，改天（月？年？）继续出去旅行]]></content>
      <tags>
        <tag>随便写写</tag>
        <tag>吐槽</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql索引及查询优化（一）——从慢查询实例中开始分析]]></title>
    <url>%2F2018%2F08%2F04%2F20180804-sqlIndexAndQueryOptimize-1%2F</url>
    <content type="text"><![CDATA[官方吐槽为什么写这个写这个博客也算是阴差阳错。上次做了个需求：退款列表导出（可以翻翻之前的博客，有写）。虽然事情过了那么久，现在我还是想要吐槽下，这个需求是真的有很多坑，但话说回来，做难事才会有所得，踩的坑越多，那成长就越多（请脑补虐主文）。 关于这个系列的博客这个博客大概是这么分布的：第一篇就根据实际场景来分析下索引及查询上的优化；第二篇和第三篇（如果我还能写得出来第三篇的话😅）来系统地整理下mysql的索引及查询的优化。 ———————————— 以下为正文 —————————————问题是这样的，有一次一个客服同学急急忙忙来找我，说导出几条记录都失败了，查看了错误日志显示错误如下： 好了，不要盯着人家的红色框框看了，重点不是那里。 重点是出现了慢查询日志，我知道看图肯定看不出来这条sql是啥，于是我贴心的贴了出来： 1234567select* （这里其实不是这么暴力地拿全列数据，为了方便，就*表示了）from RefundFORCE INDEX (idx_sellerUserId_created_status)WHERE sellerUserId = 40955202 AND status IN (800, 900) AND created &gt;= 946656000 AND created &lt; 2051193600 ORDER BY created desc LIMIT 0, 50 首先来分析下这条sql要做啥，其实就是在Refund（退款表）这个表中查询所有sellerUserId为40955202，并且状态在800及900（800，900等表示退款处于的状态，如退款申请，退款完成等）之间的，并且创建时间大于等于946656000且小于2051193600（这是两个时间戳）的所有记录，并且将所有这些记录根据created（创建时间）进行逆序排序后取开头50条。注意到这个sql有一个 FORCE INDEX (idx_sellerUserId_created_status)，这个意思是让sql强制走idx_sellerUserId_created_status这个索引，至于为什么有时候需要强行走索引，这个涉及到mysql的查询优化，之后会讲到 看了上面这条sql，有没有发现什么问题？可能我们会觉得有问题，但是并不能很清晰地说出来。那么，首先来看下mysql的执行计划吧！ 看出问题来了么？在我看来，这条sql至少存在3条问题！以下一条一条来分析： cerated的时间查询范围过大，946656000转化为北京时间是2000/1/1 0:0:0，2051193600转化为北京时间是2035/1/1 0:0:0。那么这个时间段段含义是什么呢？在我应用的具体执行中，当用户在导出退款列表时没有选择导出的时间段时，就会给定一个默认的搜索时间段，而恰巧我设置了比较大的起止时间。这个时间段本来是不需要这么大的，这个时间段基本将这个用户所有的退款记录都包含了。我们来看下这个用户究竟有多少条退款记录：好家伙，1000多w条记录。。那么有人会说，时间段大也没关系，不是还有其他索引项可以进行约束吗？那么我们来看看第二个问题 索引真的用上了么？为了防止mysql优化器出现石志行为，这条sql特意告诉mysql：您啥也不用想！就用这个索引！那么我们来看下这个索引：idx_sellerUserId_created_status。很明显，这是一个多列索引，是一个由sellerUserId、created、status三列组成的一个联合索引。再来看下这条sql的where条件：WHERE sellerUserId = 40955202 and status IN(800, 900) and created &gt;= 946656000 AND created &lt; 2051193600 order by created。乍一看，好像索引没用上啊？索引的排序是sellerUserId、created、status，而where条件的顺序是sellerUserId、status、created。那索引是不是没用了？当然不是的！mysql如果连这点优化都没有考虑，那和咸鱼有什么区别？？在这里，mysql会将where条件做一个优化，where条件内的顺序是不影响此索引的使用的。那么这个索引真的生效了么？事实是并没有。我们来分析下这个索引，注意看这个条件：created &gt;= 946656000 AND created &lt; 2051193600，很明显这是一个范围查询，而在多列索引的使用中，如果碰到了范围条件，那么存储引擎是不会使用范围条件右边的列的，也就是说，咱们这条sql，索引到了idx_sellerUserId_created就到头了，不会再使用status做索引。强制走的这个索引，失效了！因此这条查询只用到部分的索引 查询真的有必要那么写么？我们可以看到where条件中限制了created字段的查询范围，而在排序时又需要根据created字段进行逆序排序，之后又只取了最终结果的开头50行。尽管我们很理想化地设想mysql只会返回我们需要的数据，比如在这条sql中我们真的很希望mysql可以只扫描50行就搜索我们需要的那50条数据。然而，在真正的查询中我们惊人地发现mysql读取了超过千万条的数据！一部分的原因在于查询过程中使用了不太合适的索引，另一方面在于我们的查询太累赘了，要想我们的查询不那么累赘，首先要搞清楚我们要查询什么。如上就分析过，我们需要的只是该用户创建的、处于某些状态的、最新的50条记录，那么在这种情况下created字段的范围还有什么意义？ 那么针对上面几个问题，接下来我们想办法来优化下这条查询吧！以上的截图和问题都来源于线上，因为接下来的操作可能会涉及到表结构，所以接下来使用一个线下的db来进行模拟 首先看下表的结构 然后我们来查询下退款数量最多的用户 我们发现id为93106308的用户退款数量最多，大概有5w多行，那么就用他来做模拟吧！ 首先来模拟下最初的sql语句 12345678explain select* FROM Refund FORCE INDEX (idx_sellerUserId_created_status) WHERE sellerUserId=93106308 and status IN (700, 900, 1000) AND created &gt;= 1278691200 AND created &lt; 1531152000 ORDER BY created desc LIMIT 0, 10 如上图所示的执行结果，我们可以看到，mysql确实使用了idx_sellerUserId_created_status这个索引（这其实是废话，你都强制人家走了，，），然后看rows这一行：64867！存储引擎扫描来6w多行才得到我们需要的数据！可以看到在Extra这一列中显示的是：Using index condition，这表示查询部分使用了索引，对于不在索引中的列需要回表查询数据，这也如我们预想的那样 那么我们来试试存储引擎的自动优化吧： 哈哈，存储引擎的查询优化其实并没有想象中的那么好（但也没那么差），去除了强制索引后存储引擎自己找到了一个它认为的最优的索引：idx_created，可以看到Extra这一列中显示的是：Using where，这表示查询需要回表捞数据以后再使用where条件来进行过滤。那么和上面的情况做对比，在性能上其实是毫无差别。 那我们在索引上来优化下吧，为了避免遇到范围查询而使右边索引列失效，我们来将idx_sellerUserId_created_status索引修改为idx_sellerUserId_status_created，并且让存储引擎强制走这个索引： 发现变化了么？查询扫描的行数少了很多！ 那接下来再优化下查询语句： 可以看到，因为优化了查询语句，根据created进行逆序排序，导致最后扫描的行数大为减少！ 在这里，这条查询的优化并不是在任何场景下都是能保证有很高的查询性能的。我们知道索引在db中维护了一个b+tree 结构（innodb引擎默认结构）。idx_created索引将所有的数据根据created来建立了一个b+tree，当我们要查询的用户数据恰好在b+tree的后方的时候，查询也是需要扫描不少行的： 所以不同的数据库的数据结构需要具体的分析，如果没有对表结构以及数据结构有较清晰的认识，我认为这种查询优化是不太行的，有时候甚至会起到反面效果。 所以综合考虑，我还是建议修改下索引结构即可，至于为什么不是直接增加一个索引，这是为了减小存储引擎的压力，过多的冗余索引也给维护带来负担 接下来的博客会系统地讲述下mysql的索引及查询优化 对上述问题有问题或者想一起讨论的朋友可以随时联系～]]></content>
      <tags>
        <tag>sql</tag>
        <tag>数据库</tag>
        <tag>索引</tag>
        <tag>优化</tag>
      </tags>
  </entry>
</search>
